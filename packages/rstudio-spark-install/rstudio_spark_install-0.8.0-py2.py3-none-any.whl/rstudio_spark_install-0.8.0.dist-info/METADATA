Metadata-Version: 2.0
Name: rstudio-spark-install
Version: 0.8.0
Summary: Utility to setup various versions of Apache Spark on multiple platforms.
Home-page: https://github.com/rstudio/spark-install
Author: Spark Installation authors
Author-email: authors@example.com
License: Apache
Keywords: Apache Spark PySpark Hadoop WinUtils
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 2
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.3
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5

# Introduction 
This Python script is intended to provide a smooth, cross-platform installation experience
for Spark, including WinUtils on Windows.

# Getting Started
Python 2.7 or 3.5 is required to execute this script. If installing on
Python 3.6, ensure you choose Spark version 2.1.1 or higher (see [SPARK-19109](https://issues.apache.org/jira/browse/SPARK-19019)).

Running the script with no parameters will grab the latest Spark/Hadoop combination
version available.

Command line options -sv and -hv  (or --sparkversion and --hadoopversion) allow the user
to specify exactly which version pairing to use.  Invalid pairings will present the list
of valid options to the user.


