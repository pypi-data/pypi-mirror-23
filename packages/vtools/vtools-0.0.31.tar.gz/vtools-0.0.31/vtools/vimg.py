####################################################################################################
########################################### vtools.vimg ############################################
############################################# vimg.py ##############################################
####################################################################################################
######################################## Import Statements #########################################

import atexit
import cv2
import numpy as np
import matplotlib.pyplot as plt
import mahotas

from typing import List, Dict, Tuple
from itertools import combinations
from .vtools import eprint
from .vcontours import vContour, vContours
from .config import __IDENT__
from .colors import WHITE, BLACK, GREEN, RED, BLUE, AQUA, MAROON, FUCHSIA, OLIVE, NAVY, TEAL, PURPLE, YELLOW
from .colors import vColor


####################################################################################################
########################################### vImg CLASS #############################################


class vImg(np.ndarray):

    ####################################################################################################
    ########################################## DUNDER METHODS ##########################################

    def __new__(cls, imgFn=None, **kwargs) -> np.ndarray:
        """Initiates a vImg object using np.ndarray as base class. The vImg object extends the array
        to allow for image modification methods to be executed on the base class.
        Parameters:
            imgFn = string, path to image
            **kwargs (optional, only color may be used if img is supplied)
            img    : numpy np.ndarray class or subclass type
            height : in pixels, height of the blank image
            width  : in pixels, width of the blank image
            color  : in RGB tuple, the bg color for the blank image (default: black)
            title  : string, set the title property for the image object (otherwise
                     this is generated by a sequence generator
            pass   : bool, optional, works with img parameter. Tells the initialization function
                     to check if img is a vImg. If it is, return it directly.
        """

        def blank(height : int, width : int, color=BLACK, color_type='RGB') -> np.ndarray:
            """Creates a blank image
            Parameters:
                height : int, pixel height of the blank image
                width  : int, pixel width of the blank image
                color    : tuple, RGB tuple representing the background color for the blank image 
                         (default: black). Remember, in OpenCV rgb values are stored as (B,G,R)
            """
            blank_image = np.zeros((height, width, 3), dtype='uint8')
            color = vColor(color)
            if color != BLACK: blank_image[:, :] = color
            return blank_image

        if imgFn is None:
            try:
                if kwargs.get('img', None) is not None:
                    # if the img parameter is provided
                    img = kwargs['img']
                    if kwargs.get('pass', False) and isinstance(img, vImg):
                        return img

                else:
                    # create a blank image using at least the height and width optional parameters
                    img = blank(kwargs['height'], kwargs['width'], kwargs.get('color', BLACK),
                                color_type = kwargs.get('color_type', 'RGB'))

                obj = np.asarray(img).view(cls)
                obj.__kwargs = kwargs
                obj.__h, obj.__w = obj.shape[:2]
                obj.__center = (obj.w // 2, obj.h // 2)
                obj.__color = kwargs.get('color', BLACK)
                # TODO: Add better support for multiple color types

                return obj

            except KeyError:
                str_err = "KeyError: If 'image' argument not provided, keyword arg(s) for "
                str_err += ('width and height ' if not kwargs.get('height', None) and
                                                   not kwargs.get('width', None)
                            else 'height ' if not kwargs.get('height', None)
                            else 'width ' if not kwargs.get('width', None)
                            else 'unknown property ')
                str_err += 'must be provided (color is optional).'
                eprint(str_err)
                return



        try:
            obj = np.asarray(cv2.imread(imgFn)).view(cls)
            obj.__imgFn = imgFn
            obj.__h, obj.__w = obj.shape[:2]
        except cv2.error:
            raise ValueError("OpenCV Error occurred.") from None
        except:
            raise ValueError("Unable to open file at {}. Check the file exists.".format(imgFn)) \
                  from None

        obj.__center = (obj.__w // 2, obj.__h // 2)
        obj.__color = kwargs.get('color', (0, 0, 0))
        obj.__title = kwargs.get('title', None)
        obj.__kwargs = kwargs
        obj.__kwargs['imgFn'] = f"'{imgFn}'"
        return obj

    def __array_finalize__(self, obj):
        if obj is None: return
        self.__h = getattr(obj, '__h', None)
        self.__w = getattr(obj, '__w', None)
        self.__center = getattr(obj, '__center', None)
        self.__color = getattr(obj, '__color', None)
        self.__color_type = getattr(obj, '__color_type', 'RGB')
        self.__title = getattr(obj, '__title', None)
        self.__imgFN = getattr(obj, '__imgFN', None)
        self.__kwargs = getattr(obj, '__kwargs', None)
        self.__cDict = {'b': 'Blue', 'g': 'Green', 'r': 'Red'}
        self.__current_title = self.__title

    def __array_wrap__(self, out_arr, context=None):
        """__array_wrap__ gets called at the end of numpy ufuncs and
        other numpy functions, to allow a subclass to set the type of
        the return value and update attributes and metadata"""
        out_arr.__h = self.__h
        out_arr.__w = self.__w
        out_arr.__center = self.__center
        out_arr.__color = self.__color
        out_arr.__color_type = self.__color_type
        out_arr.__title = self.__title
        out_arr.__imgFN = self.__imgFN
        out_arr.__kwargs = self.__kwargs
        out_arr.__cDict = {'b': 'Blue', 'g': 'Green', 'r': 'Red'}
        out_arr.__current_title = self.__title

        return np.ndarray.__array_wrap__(self, out_arr, context)

    def __eq__(self, other):
        return np.array_equal(self, other)

    def __copy__(self):
        return vImg(img=self)

    def __repr__(self):
        """ Repr reproduces the expression that created the image object as exactly as possible, a notable
        limitation is that when built using a local path, the object reproduces the local path used.
        May change this behavior in the future to just return the string representation of the image array,
        but this method is usually much more readable.
        """
        key_words = ', '.join(f'{k} = {i}' for k,i in self.__kwargs.items())

        return f'vImg({key_words})'


    ####################################################################################################
    ######################################### IMAGE PROPERTIES #########################################

    @property
    def h(self):
        if self.__h is None:
            self.__h = self.shape[0]
        return self.__h

    @h.setter
    def h(self, val):
        self.__h = val

    @property
    def w(self):
        if self.__w is None:
            self.__w = self.shape[1]
        return self.__w

    @w.setter
    def w(self, val):
        self.__w = val

    @property
    def height(self):
        return self.h

    @height.setter
    def height(self, val):
        self.h = val

    @property
    def width(self):
        return self.w

    @width.setter
    def width(self, val):
        self.w = val

    @property
    def center(self):
        if self.__center is None:
            self.h, self.w = self.shape[:2]
            self.__center = (self.w // 2, self.h // 2)
        return self.__center

    @property
    def color(self):
        return self.__color

    @color.setter
    def color(self, val):
        self.__color = val

    @property
    def color_type(self):
        return self.__color_type

    @property
    def title(self):
        if self.__title is None:
            self.title = 'img' + next(__IDENT__)
        return self.__title

    @title.setter
    def title(self, val):
        assert isinstance(val,str), 'Title must be of type string'
        self.__title = val

    ####################################################################################################
    ################################### GENERAL TRANSFORMATION TOOLS ###################################
    ###################### Reused very little of Dr. Adrian Rosebrock's code and #######################
    ########################### comments from his excellent package imutils ############################
    #########################  and book 'Practical Python and OpenCV' below.  ##########################

    def BGR2RGB(self):
        image = cv2.cvtColor(self.copy(), cv2.COLOR_BGR2RGB)
        return vImg(img=image)

    def RGB2BGR(self):
        image = cv2.cvtColor(self.copy(), cv2.COLOR_RGB2BGR)
        return vImg(img=image)

    def gray(self):
        """ function that returns a grayscale transformed from BGR version of the vImg object """
        gray = cv2.cvtColor(self.copy(), cv2.COLOR_BGR2GRAY)
        return vImg(img=gray)

    def BGR2HSV(self):
        image = cv2.cvtColor(self, cv2.COLOR_BGR2HSV)
        return vImg(img=image)

    def grayHSV(self):
        """ function that returns a grayscale transformed from HSV version of the vImg object """
        V = cv2.split(self.BGR2HSV())[2] # grab the third element (the value channel)
        return vImg(img=V)

    def translate(self, x : int, y : int):
        """ function that returns translated (shifted by x and y pixels) image
        x : int, number of pixels to move the image horizontally (positive right, negative left)
        y : int, number of pixels to move the image vertically (positive down, negative up)
        """
        # Define the translation matrix and perform the translation
        M = np.float32([[1, 0, x], [0, 1, y]])
        shifted = cv2.warpAffine(self, M, (self.shape[1], self.shape[0]))
        # Return the translated image
        return vImg(img=shifted)

    def rotate(self, angle : int = 90, center = None, scale : float = 1.0):

        if not center: center = self.center
        # Perform the rotation
        M = cv2.getRotationMatrix2D(center, angle, scale)
        rotated = cv2.warpAffine(self, M, (self.w, self.h))

        # Return the rotated image
        return vImg(img=rotated)

    def resize(self, width = None, height = None, interpolation = cv2.INTER_AREA):
        """ function that returns a resized image based on a given width, height, or both.
        Maintains the aspect ratio of the image if given only one dimension.
        width  : int, optional, width in pixels for the resized image
        height : int, optional, height in pixels for the resized image
        inter  : cv2 CONSTANT, optional, interpolation method
        Valid values for inter:
        cv2.INTER_AREA (default)
        cv2.INTER_NEAREST
        cv2.INTER_CUBIC
        cv2.INTER_LINEAR
        cv2.INTER_LANCZOS4
        """
        # initialize the dimensions of the image to be resized and grab the image size
        h, w = self.shape[:2]

        # if both the width and height are None, then return the original image
        if width is None and height is None:
            return vImg(img=self)

        # check to see if the width is None
        if height is not None and width is not None:
            dim = (width, height)

        elif width is None:
            # calculate the ratio of the height and construct the dimensions
            r = height / float(h)
            dim = (int(w * r), height)

        # otherwise, the height is None
        else:
            # calculate the ratio of the width and construct the dimensions
            r = width / float(w)
            dim = (width, int(h * r))

        # resize the image
        resized = cv2.resize(self.copy(), dim, interpolation=interpolation)

        # set the new state and img of the resized img
        return vImg(img=resized)

    ####################################################################################################
    ##################################### MORPHOLOGICAL OPERATIONS #####################################

    def erode(self,  iterations : int = 1, k_size : Tuple[int, int] = (3, 3), k_type : int = cv2.MORPH_RECT):
        """ Performs the erosion morphological operation on the image. Assumes caller is a binary image.
        Erodes the foreground object and makes it smaller.

        :param int         iterations : Number of iterative 'erosions' to perform
        :param Tuple[int, int] k_size : size of the kernel, first is the width, then height in pixels
        :param int             k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                        defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg                  :
        """
        kernel = cv2.getStructuringElement(k_type, k_size)
        erode_img = self.copy()
        return vImg(img=cv2.erode(erode_img, kernel, iterations = iterations))


    def dilate(self,  iterations : int = 1, k_size : Tuple[int, int] = (3, 3), k_type : int = cv2.MORPH_RECT):
        """ Counter to the erode function, dilate is a morphological operation that results in the foreground pixels
        'growing'. Dilations increase the size of a foreground object and are especially useful for joining broken
        parts of an image together.


        :param int         iterations : Number of iterative 'dilations' to perform
        :param Tuple[int, int] k_size : size of the kernel, first is the width, then height in pixels
        :param int             k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                        defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg                  :

        """
        kernel = cv2.getStructuringElement(k_type, k_size)
        dilate_img = self.copy()
        return vImg(img=cv2.dilate(dilate_img, kernel, iterations = iterations))

    def open(self, k_size : Tuple[int, int] = (3, 3), k_type : int = cv2.MORPH_RECT):
        """ An opening is an erosion followed by a dilation. Used to remove small undesirable blobs from an image.
        The erosion is applied first to remove the small blobs, then a dilation is applied to regrow the size of the
        original object.

        :param Tuple[int, int] k_size : size of the kernel, first is the width, then height in pixels
        :param int             k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                        defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg                  :
        """
        kernel = cv2.getStructuringElement(k_type, k_size)
        return vImg(img=cv2.morphologyEx(self.copy(), cv2.MORPH_OPEN, kernel))

    def close(self, k_size : Tuple[int, int] = (3, 3), k_type : int = cv2.MORPH_RECT):
        """ A closing is the opposite of an opening: a dilation followed by an erosion. Typically used to close holes
        inside of objects or for connecting components together. The dilation is applied first to close a hole or
        connect components and is followed by an erosion to restore the original size of the object.

        :param Tuple[int, int] k_size : size of the kernel, first is the width, then height in pixels
        :param int             k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                        defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg                  :
        """
        kernel = cv2.getStructuringElement(k_type, k_size)
        return vImg(img=cv2.morphologyEx(self.copy(), cv2.MORPH_CLOSE, kernel))

    def morphGradient(self, k_size : Tuple[int, int] = (3, 3), k_type : int = cv2.MORPH_RECT):
        """ The distance between the dilation and erosion, which is useful for determining the outline of an erosion,
        which in turn is useful for determining the outline of a particular object in an image.

        :param Tuple[int, int] k_size : size of the kernel, first is the width, then height in pixels
        :param int             k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                        defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg                  :
        """
        kernel = cv2.getStructuringElement(k_type, k_size)
        return vImg(img=cv2.morphologyEx(self.copy(), cv2.MORPH_GRADIENT, kernel))

    def blackHat(self, k_size : Tuple[int, int] = (3, 3), k_type : int = cv2.MORPH_RECT):
        """ The black hat operation is the difference between the closing operation and the original image,
        which is the opposite of the top hat operation. Black hat and Top hat MOs are best used on grayscale images.
        Black hat operations are typically used to reveal dark regions of an image on a bright (or white) background.

        :param Tuple[int, int] k_size : size of the kernel, first is the width, then height in pixels
        :param int             k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                        defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg                  :
        """
        kernel = cv2.getStructuringElement(k_type, k_size)
        return vImg(img=cv2.morphologyEx(self.copy(), cv2.MORPH_BLACKHAT, kernel))

    def topHat(self, k_size : Tuple[int, int] = (3, 3), k_type : int = cv2.MORPH_RECT):
        """ The white hat operation returns the difference between the original image and the opening MO. Top hat and
        black hat MOs are best used on grayscale images. Top hat operations are typically used to reveal bright
        regions of an image on dark backgrounds.

        :param Tuple[int, int] k_size : size of the kernel, first is the width, then height in pixels
        :param int             k_type : k_type (or kernel type) refers to a the shape of the kernel.
                                        defaults to cv2.MORPH_RECT, could also be cv2.MORPH_CROSS or cv2.MORPH_ELLIPSE
        :return vImg                  :
        """
        kernel = cv2.getStructuringElement(k_type, k_size)
        return vImg(img=cv2.morphologyEx(self.copy(), cv2.MORPH_TOPHAT, kernel))

    ####################################################################################################
    ########################################## BLURRING TOOLS ##########################################

    def blur(self, k_size : Tuple[int, int] = (5, 5)):
        """ blur takes some input and returns a Average Blurred version of the image.
        The average blurring process is so named because we take a box called a "convolution
        kernel" of k x k pixels. Starting at one corner of the image, it slides left to right
        and up to down one pixel at a time, each time it moves calculating the average of all
        pixel intensities inside the kernel, then replacing the value of the central pixel in
        the kernel in the output image with the computed average.

        :param tuple k_size: tuple(2int) size of the kernel used in calculating the pixel
                                  intensity average. Must be a tuple of two odd integers
        :return vImg            : The new blurred image
        """

        return vImg(img=cv2.blur(self.copy(), k_size))

    def GaussianBlur(self, k_size : Tuple[int, int] = (5, 5), sigma = 0):
        """ GuassianBlur takes some input and returns a Gaussian Blurred version of the image.
        Gaussian blurring is similar to average blurring, but the nearer the pixel is to
        the kernel's center, to the greater the weight that is applied to that pixel's value.

        Gaussian Blur is effective at mitigating noise in high frequency edges and eliminating
        noise that follows a gaussian distribution.

        :param tuple k_size: tuple(2int) size of the kernel used in calculating the pixel
                                  intensity average. Must be a tuple of two odd integers
        :param             sigma: The standard deviation in the x-axis direction. By setting
                                  this value to zero (or leaving it default), OpenCV will
                                  automatically calculate sigma based on kernel size.
        :return vImg            : The new blurred image
        """

        return vImg(img=cv2.GaussianBlur(self.copy(), k_size, sigma))

    ####################################################################################################
    ######################################## THRESHOLDING TOOLS ########################################

    def threshold(self, T : int, k : int = 5, inverse = True):
        """ We will apply binary thresholding from the current image object and return the second result
        i.e. the threshold map. This method is very basic and requires manual tuning of the T value for each
        image in order to obtain usable results.
        T : int, threshold pixel intensity
        k : kernel size in square pixels for gaussian blur, default to 5
        inverse: bool, whether or not to return an inverse binary threashold, default YES
        """
        # The value of k must be odd so that there's a center pixel in the matrix
        if k % 2 == 0: raise ValueError(f'k must be an odd number... not {k}') from None

        # Check if the image is black and white, if it isn't, convert it
        image = self
        if len(self.shape) > 2:
            image = self.gray()

        # First, apply a gaussian blur
        gauss = image.GaussianBlur((k,k), 0)

        # Next, apply the threshold to the image
        thresh_bin = cv2.THRESH_BINARY_INV if inverse is True else cv2.THRESH_BINARY
        thresh = cv2.threshold(gauss, T, 255, thresh_bin)[1]

        # Finally, return the result
        return vImg(img=thresh)

    def adaptiveThreshold(self, adaptive_method = cv2.ADAPTIVE_THRESH_GAUSSIAN_C, neighborhood = 25,
                          k = 5, C = 0, inverse = True):
        """ Applies adaptive thresholding to the image object and return a threshold map based off of a
        given neighborhood size.
        :param int adaptive_method : cv2 constant that represents which adaptive thresholding method we will
                                     use (e.g. cv2.ADAPTIVE_THRESH_MEAN_C, cv2.ADAPTIVE_THRESH_GAUSSIAN_C)
        :param int    neighborhood : default 25, size of the neighborhood in which to evaluate small areas
                                     of pixels in order to find an optimal value of T to apply thresholding
        :param int               k : kernel size in square pixels for gaussian blur, default to 5
        :param int               C : subtracted from the mean, giving us granular control of the adaptive
                                     thresholding process, default to 0
        :param bool        inverse : bool, value representing whether or not the threshold constant used will
                                     be inverse or normal. Inverse is default since it's commonly used for
                                     masking.
        """
        # The value of k must be odd so that there's a center pixel in the matrix
        if k % 2 == 0 or k < 3: raise ValueError(f'[Error] Parameter k must be odd and greater than one. Got {k}')

        # First, assert the color of the image is grayscale, then apply a gaussian blur
        assert len(self.shape) == 2, "Must use on grayscale image"
        gauss = cv2.GaussianBlur(self, (k,k), 0)

        # determine whether to use standard or inverse binarization method
        thresh_bin = cv2.THRESH_BINARY if not inverse else cv2.THRESH_BINARY_INV

        # Next, apply the threshold to the image
        thresh = cv2.adaptiveThreshold(gauss, 255, adaptive_method, thresh_bin, neighborhood, C)

        # Return the new vImg object
        return vImg(img=thresh)

    ####################################################################################################
    ########################################## GRADIENT TOOLS ##########################################

    def Laplacian(self):
        """Performed on a grayscale image, returns the Laplacian gradient of the image.
        :return: 
        :rtype: vImg
        """
        lap = cv2.Laplacian(self, cv2.CV_64F)
        lap = np.uint8(np.absolute(lap))
        return vImg(img=lap)

    def SobelX(self):
        """Performed on a grayscale image, returns the Sobel gradient image along the X axis
        :return: 
        :rtype: vImg
        """
        # Calculate the Sobel gradient along the X-axis
        SobelX = cv2.Sobel(self, cv2.CV_64F, 1, 0)
        return vImg(img=SobelX)

    def SobelY(self):
        """Performed on a grayscale image, returns the Sobel gradient image along the Y axis
        :return: 
        :rtype: vImg
        """
        # Calculate the Sobel gradient along the Y-axis
        SobelY = cv2.Sobel(self, cv2.CV_64F, 0, 1)
        return vImg(img=SobelY)

    def sobelCombined(self):
        """Performed on a grayscale image, returns the Sobel gradient image along both axes.
        :return: 
        :rtype: vImg
        """

        # Calculate the Sobel gradient along the X-axis
        sobelX = cv2.Sobel(self, cv2.CV_64F, 1, 0)
        # Calculate the Sobel gradient along the Y-axis
        sobelY = cv2.Sobel(self, cv2.CV_64F, 0, 1)

        sobelBoth = cv2.bitwise_or(sobelX, sobelY)

        return vImg(img=sobelBoth)

    ####################################################################################################
    ######################################## EDGE MAPPING TOOLS ########################################

    def autoCanny(self, sigma : float = 0.33 ):
        # compute the median of the single channel pixel intensities
        v = float(np.median(self))

        # apply automatic Canny edge detection using the computed median
        lower = int(max(0., (1.0 - sigma) * v))
        upper = int(min(255., (1.0 + sigma) * v))
        edged = cv2.Canny(self, lower, upper)

        # return the edged image
        return vImg(img=edged)

    ####################################################################################################
    ########################################## CONTOUR TOOLS ###########################################

    def simpleContours(self, quantity = cv2.RETR_EXTERNAL, complexity = cv2.CHAIN_APPROX_SIMPLE):
        """Performs simple cv2.findContours operation using common but overridable default 
           parameters on a vImg object, returns a list of vContour
        
        quantity    : cv2.RETR_EXTERNAL (default), also could be: cv2.RETR_LIST, cv2.RETR_COMP, 
                      and cv2.RETR_TREE
        complexity  : cv2.CHAIN_APPROX_SIMPLE (default), also could be: cv2.CHAIN_APPROX_NONE
        
        Passes the second element returned from cv2.findContours to the vContour class's fromList
        builder. Returns a vContours list of vContour objects. 
        
        Returns the 2nd element because the first element returned by cv2.findContours is 
        a 'destroyed' version of the image passed to it.
        """
        try:
            return vContour.fromList(cv2.findContours(self.copy(), quantity, complexity)[1])
        except cv2.error:
            eprint("\nOpenCV Error: likely tried to use image that has not been thresholded. \n"
                  "Now attempting to continue this operation using autoCanny(). \n"
                  "To avoid this error message, pass only edge maps to the simpleContours() function,\n"
                  "e.g. vImg('test.png').autoCanny().simpleContours()\n")
            return vContour.fromList(cv2.findContours(self.autoCanny(), quantity, complexity)[1])

    def evalContours(self, cnts = None, count = None, reverse = True, outline_color = GREEN, font_color = WHITE):
        """This function exists to make it easier to evaluate contours in an image. Calling this
        function and supplying a list of contours iterates through the list of contours and
        identifies them one at a time on the image while simultaneously displaying useful
        simple and advanced contour properties in the console.
        
        Very useful for determining if contour analysis may be used effectively in a given 
        application. Not generally applicable or useful in a production environment.
        
        cnts          : vContours object (list of vContour), use the simpleContours method to 
                        easily generate a vContours object
        count         : int, if supplied, the contours will be sorted and count will determine 
                        how many are returned
        reversed      : bool, defaults to False, if set True when called, contours will be 
                        size-sorted in reverse (big to small) before being truncated to count 
                        number of contours.
        outline_color : tuple (3 unsigned 8-bit integers), 3-tuple indicating color of outline 
                        in RGB format
        font_color    : tuple (3 unsigned 8-bit integers), 3-tuple indicating color of label 
                        text in RGB format
        """

        if cnts is None:
            cnts = self.simpleContours()

        assert isinstance(cnts, vContours), 'Must be vContours iterable'

        if count is not None:
            cnts.sizeSort(reverse=reverse)
            cnts = cnts[:count]

        if not isinstance(outline_color, vColor):
            outline_color = vColor(outline_color)

        if not isinstance(font_color, vColor):
            font_color = vColor(font_color)

        img = self.copy()

        for i, c in enumerate(cnts):
            cv2.drawContours(img, [c], -1, outline_color.BGR(), 1)
            cv2.putText(img, f'#{i}', (c.x, c.y - 5), cv2.FONT_HERSHEY_SIMPLEX,
                        0.5, font_color.BGR(), 2)
            print(f"""Shape #{i} @ x({c.x},{c.x2}) y({c.y}, {c.y2})
            --------------------------------------------------------------
            width: {c.width} height: {c.height}
            Aspect Ratio is (image width / image height): {c.aspect_ratio:.2f}
            Contour Area is: {c.area:.2f}
            Bounding Box Area is: {c.w * c.h:.2f}
            Convex Hull Area is: {c.hull_area:.2f}
            Solidity (Contour Area / Convex Hull Area) is: {c.solidity:.2f} 
            Extent (Contour Area / Bounding Box Area) is: {c.extent:.2f}
            Center is located at: {c.center}""")
            cv2.imshow(self.title, img)
            cv2.waitKey(0)
        atexit.register(cv2.destroyAllWindows)

    ####################################################################################################
    ######################################### HISTOGRAM TOOLS ##########################################

    def histFlat(self, RGB = (True,)*3, mask = None, bins = (256,), xlimit = (0, 256),
                 normal = True, display = True):
        """ By adding a single 3-tuple bool parameter (RGB) to indicate which channels are active 
        in the histogram, we can make showing different types of histograms trivial.
        """

        if not isinstance(bins, list):
            bins = list(bins)

        if not isinstance(xlimit, list):
            xlimit = list(xlimit)

        # TODO: Make sure changing bins and xlimit to tuple doesn't have ill effects on function call

        results = {}
        # Check if image is grayscale
        assert RGB != (False, False, False), "To get a grayscale histogram from a color image, " \
                                             "first convert to grayscale using the gray() method"

        if len(self.shape) == 2: # 1-dimensional grayscale image
            if display:
                plt.figure()
                plt.title(f"'Flattened' Grayscale Histogram ('{self.title}')")
                plt.xlabel("Bins")
                plt.ylabel("# of Pixels")

            hist = cv2.calcHist([self], [0], mask, bins, xlimit)

            if normal:
                hist /= hist.sum()

            if display:
                plt.plot(hist, color='k')
                plt.xlim(xlimit)

            results.update({'k' : hist})

        elif len(self.shape) == 3: # 2-dimensional image with at least 1 color channel

            channels = cv2.split(self)
            colors = ('b', 'g', 'r')
            cczip = tuple(e for e in zip(channels, colors, RGB[::-1]) if e[2] is True)

            if display:
                plt.figure()

            *chans, final_chan = [self.__cDict[e[1]] for e in cczip]

            if display:
                plt.title('Flattened Color Histogram for color channels '
                          f"{' '.join(e for e in chans)}, and {final_chan} ('"
                          f"{self.title}').")
                plt.xlabel("Bins")

                if normal:
                    plt.ylabel("Percentage of total")
                else:
                    plt.ylabel("# of Pixels")

            for chan, clr, _ in cczip:
                hist = cv2.calcHist([chan], [0], mask, bins, xlimit)

                if normal:
                    hist /= hist.sum()

                if display:
                    plt.plot(hist, color=clr)
                    # plt.xlim(xlimit) already specified

                results.update({ clr : chan })

        return results

    def hist2D(self, RGB = (True,)*3, mask = None, bins = (32, 32),
               xlimit = (0, 256, 0, 256), display = True):
        """ Function for creation/viewing a two-dimensional histogram
        
        """
        #TODO: Make sure changing bins and xlimit to tuple doesn't have ill effects on function call

        if not isinstance(bins, list):
            bins = list(bins)

        if not isinstance(xlimit, list):
            xlimit = list(xlimit)
        assert len(self.shape) > 2, "Two dimensional histograms must not be grayscale"

        horizontal_subchannels = len([e for e in RGB if e is True])


        if horizontal_subchannels == 3:
            fig, axs = plt.subplots(1, 3) # sharey = False, sharex = False
        else:
            fig = plt.figure()

        i = 0

        colors = ('B', 'G', 'R')
        # split the channels of the image into the RGB components
        channels = cv2.split(self)
        # create a list that contains each color that needs to be tested, a string representation
        # of that color, and a bool representing whether that color is included, filter out False
        # (colors,
        cczip = (e for e in zip(channels, colors, RGB[::-1]) if e[2] is True)
        # Create generator for all unique combinations of colors that are included

        channels = combinations(((chan, color) for chan, color, _ in cczip), 2)

        # eprint(f'{"itertools.combinations" in sys.modules}')
        # eprint(f'{"itertools" in sys.modules}')
        results = {}
        for (chan1, color1), (chan2, color2) in channels:
            hist = cv2.calcHist([chan1, chan2], [0, 1], mask, bins, xlimit)
            if horizontal_subchannels == 3 and display:
                # subplot_num = 100 + 10 * horizontal_subchannels + i
                # ax = fig.add_subplot(subplot_num)
                axs[i].set_title(f"2D Color Histogram for {color1} and {color2}")
                p = axs[i].imshow(hist, interpolation="nearest")
                fig.colorbar(p, ax=axs[i])
                i += 1

            elif display:
                plt.title(f"2D Color Histogram for {color1} and {color2}")
                plt.xlim(xlimit)
                p = plt.imshow(hist, interpolation="nearest")
                plt.colorbar(p)

            results.update({ (color1, color2) : hist })

        return results

    def hist3D(self, mask = None, bins = (8, 8, 8), xlimit = (0, 256, 0, 256, 0, 256), display = True):
        """ Function that returns a three dimensional histogram based on the current image object using 
        the OpenCV calcHist function. 
        :param mask    :
        :param bins    :
        :param xlimit  :
        :param display : 
        
        """

        # TODO: Make sure changing bins and xlimit to tuple doesn't have ill effects on function call

        if not isinstance(bins, list):
            bins = list(bins)

        if not isinstance(xlimit, list):
            xlimit = list(xlimit)

        hist = cv2.calcHist([self], [0, 1, 2], mask, bins, xlimit)

        if display:
            print(f"3D histogram shape: {hist.shape}, with {hist.flatten().shape[0]} values")

        return hist

    def equalizeHist(self, error_on_color = False):

        if len(self.shape) == 2:
            return vImg(img=cv2.equalizeHist(self))
        else:
            if error_on_color:
                raise ValueError("Histogram equalization requires histogram to be grayscale")
            else:
                return vImg(img=cv2.equalizeHist(self.gray()))

    ####################################################################################################
    ####################################### MASKING AND CROPPING #######################################

    def blankMask(self, zeros : bool = True):
        """ Return a blank 1-channel mask the size of the original image."""
        return np.zeros(self.shape[:2], dtype="uint8") if zeros is True \
               else np.ones(self.shape[:2], dtype="uint8") * 255

    def vContoursMask(self, cnts: vContours, index: int = -1, value: int = 255, thickness: int = -1):
        """ Creates a mask from a list of vContours,

        :param vContours   cnts: Parent image used to create mask from contours
        :param int        index: Default -1 (all), optionally provide a specific contour for the mask
        :param int        value: Default 255, optionally override the pixel mask value
        :param int    thickness: Default -1 (solid), optionally return mask of given thickness around contour
        :return            vImg: Returns a vImg
        """

        # Create blank mask
        mask = self.blankMask()

        # Call draw contours to create the mask from the vContours list
        cv2.drawContours(mask, cnts, index, value, thickness)

        return vImg(img=mask)

    def ROI(self, c : vContour):
        """ returns a slice of an image corresponding to a vContour's x, y, w, and h properties
        :param vContour    c: vContour on which to base the dimensions of the returned cropped image
        :return vImg        : vImg cropped to the boundaries of the vContour passed to it
        """

        assert isinstance(c, vContour), 'Must be vContour.'

        try:
            return self[c.y : c.y2, c.x : c.x2]

        except Exception:
            eprint('[Error] are you sure this contour belongs to this image?')

    ####################################################################################################
    ############################################# MOMENTS ##############################################

    def moments(self):
        return cv2.moments(self).flatten()

    def HuMoments(self):
        """ Returns the Hu Moments calculated by the opencv library in the form of a flattened
        list of seven moments.
        """
        return cv2.HuMoments(cv2.moments(self)).flatten()

    def ZernikeMoments(self, radius, degree=8, center_of_mass=None):
        """
        Copyright (C) 2006-2014, Luis Pedro Coelho <luis@luispedro.org>
        License: MIT

        zvalues = zernike_moments(im, radius, degree=8, cm={center_of_mass(im)})
        Zernike moments through ``degree``. These are computed on a circle of
        radius ``radius`` centered around ``cm`` (or the center of mass of the
        image, if the ``cm`` argument is not used).
        Returns a vector of absolute Zernike moments through ``degree`` for the
        image ``im``.
        Parameters
        ----------
        im : 2-ndarray
            input image
        radius : integer
            the maximum radius for the Zernike polynomials, in pixels. Note that
            the area outside the circle (centered on center of mass) defined by
            this radius is ignored.
        degree : integer, optional
            Maximum degree to use (default: 8)
        cm : pair of floats, optional
            the centre of mass to use. By default, uses the image's centre of mass.
        Returns
        -------
        zvalues : 1-ndarray of floats
            Zernike moments
        References
        ----------
        Teague, MR. (1980). Image Analysis via the General Theory of Moments.  J.
        Opt. Soc. Am. 70(8):920-930.
        """
        if not center_of_mass:
            return mahotas.features.zernike_moments(self, radius, degree)

        else:
            return mahotas.features.zernike_moments(self, radius, degree, center_of_mass)

    ####################################################################################################
    ###################################### OBJECT DETECTION TOOLS ######################################

    def connectedComponents(self, connectivity = 8, type = cv2.CV_32S):
        """ Perform connected component analysis and return a matrix of labels corresponding
        to the found objects in the analyzed image. 0 represents background, while integers 
        above zero correspond to the label of a single found object.
                
        :param connectivity : int, 8 or 4 for 8-way or 4-way connectivity, respectively
        :param type         : Currently CV_32S and CV_16U are supported.
        :return             : mat of labels corresponding to the found components
        """

        return cv2.connectedComponents(self, connectivity, type)[1] # only return the label matrix


    def pyramid(self, scale=1.5, min_size=(64, 64)):
        """ Generator that returns successively smaller versions of an image object until a supplied
        minimum size is reached.
        :param scale   : float, The denominator by which the width of the image is successively divided.
        :param min_size : 2-tuple of integers, (minY, minX), minimum dimensions for the image, if the 
                         image is made smaller than these supplied dimensions the generator ends.
        :return        : yields successively smaller images until a minimum is reached, based on the 
                         supplied parameters.
        """
        # yield the original self
        yield self

        # need the following line to make sure self doesn't refer to the original object's state,
        # which results in an infinite loop
        image = self

        # separate the values from min_size for clarity
        minX, minY = min_size

        # keep looping over the pyramid
        while True:
            # compute the new dimensions of the self and resize it
            w = int(image.w / scale)

            # the following line always resizes from the original object (self) to avoid a
            # recursive reduction in quality. w always gets smaller so image also gets
            # successively reduced in size.
            image = self.resize(width=w)

            # if the resized image becomes smaller than the supplied minimum allowed
            # size, then stop constructing the pyramid
            if image.h < minY or image.w < minX:
                return

            # yield the next image in the pyramid
            yield image

    def slidingWindow(self, step_size = 32, window_size = (64, 64)):
        # slide a window across the image, yielding the current window

        yield from ((x, y, self[y:y + window_size[1], x:x + window_size[0]])
                    for y in range(0, self.h, step_size)
                    for x in range(0, self.w, step_size))

    def slidingPyramidChain(self, scale = 1.5, min_size = (64, 64), step_size = 32,
                                  window_size = (64, 64)):
        """
        
        :param scale       : 
        :param min_size    : 
        :param step_size   : 
        :param window_size : 
        :return            : 
        """

        yield from ((x, y, window, layer) for layer in self.pyramid(scale, min_size)
                    for x, y, window in layer.slidingWindow(step_size, window_size))


    ####################################################################################################
    ####################################### IMAGE DISPLAY TOOLS ########################################

    def show(self, title = None, wait = 0, waitKey = True, destroy = True):
        """ Display the image using opencv's imshow functions. Also optionally follows that command
        up with the waitKey function with an optionally provided wait time. Always registers the
        cv2.destroyAllWindows function to run at program exit to ensure cleanup.
        
        :param str    title : Optional, string, represents an optionally provided custom title for the window
                         in which the image is displayed. If this is not provided, the image's title
                         property is used for the window instead. Does not set the title.
        :param int     wait : Optional, int (default is 0), represents the number of seconds provided to the
                         cv2.waitKey function.
        :param bool waitKey : Optional, bool (default is True), set this parameter to False to disable invoking
                         the cv2.waitKey function.
        :param bool destroy : Optional, bool (default is True), set this parameter to False to disable registering
                         cv2.destroyAllWindows at exit.
        """
        # TODO: Any negative effects from using atexit functionality to always run destroyAllWindows?

        if title is None:
            title = self.title

        self.__current_title = title

        cv2.imshow(title, self)

        if waitKey:
            cv2.waitKey(wait)

        if destroy:
            atexit.register(cv2.destroyAllWindows)

    def putText(self, text, loc, font = cv2.FONT_HERSHEY_SIMPLEX, font_scale = 1.0, color = GREEN,
                thickness = 2, line_type = None, copy = True):
        """

        :param str         text :
        :param tuple        loc :
        :param int         font :
        :param float font_scale :
        :param vColor     color :
        :param int    thickness :
        :param        line_type :
        :param bool        copy :
        :return                 :
        """

        result = None

        if copy is True:
            result = vImg(img=cv2.putText(self, f"{text}", loc, font, font_scale, color, thickness))

        else:
            cv2.putText(self, f"{text}", loc, font, font_scale, color, thickness)

        return result

    def hide(self):
        """ Attempt to kill a currently open image """
        try:
            cv2.destroyWindow(self.__current_title)

        except cv2.error:
            eprint('\n[+] OpenCv Error prevented closing of requested window.\n')


