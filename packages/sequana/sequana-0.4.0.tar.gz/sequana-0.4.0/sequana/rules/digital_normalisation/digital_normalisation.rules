rule digital_normalisation:
    """ Assembly is very hard with ultra-deep sequencing data. Digital
    normalisation is a method to normalise coverage of a sample without
    reference. It provides as good or better results than assembling the
    unnormalised data.

    Required input:
        - __digital_normalisation__input: list of paired fastq files

    Required output:
        - __digital_normalisation__output: list of paired fastq files

    Required parameters:
        - __digital_normalisation__prefix: output prefix
        - config["digital_normalisation"]["ksize"]: kmer size used to 
            normalised the coverage.
        - config["digital_normalisation"]["cutoff"]: when the median k-mer
            coverage level is above this number the read is not kept.
        - config["digital_normalisation"]["max_memory_usage"]: maximum amount
            of memory to use for data structure.
        - config["digital_normalisation"]["threads"]: number of threads to be
            used.
        - config["digital_normalisation"]["options"]: any options recognised by
            normalize-by-median.py.

    Logs:
        - __digital_normalisation__log
    """
    input:
        fastq = __digital_normalisation__input
    output:
        fastq_dn = __digital_normalisation__output,
        graph = temp(__digital_normalisation__prefix + "/graph.ct")
    log:
        __digital_normalisation__log
    params:
        prefix = __digital_normalisation__prefix,
        ksize = config["digital_normalisation"]["ksize"],
        cutoff = config["digital_normalisation"]["cutoff"],
        m = config["digital_normalisation"]["max_memory_usage"],
        options = config["digital_normalisation"]["options"]
    threads:
        config["digital_normalisation"]["threads"]
    shell:
        """
        # Files name without .gz extension
        fastq="{input.fastq}"
        fastq=${{fastq//.gz/}}
        echo $fastq

        # Uncompress fastq file
        unpigz -fk {input.fastq} -p {threads}

        # concatenate R1 and R2
        interleave-reads.py $fastq --output {params.prefix}.pe > {log} 2>&1

        # digital norm
        normalize-by-median.py --paired --ksize {params.ksize} \
            --cutoff {params.cutoff} -M {params.m} {params.options} \
            --savegraph {output.graph} {params.prefix}.pe \
            --output {params.prefix}.pe.keep >> {log} 2>&1

        # filter abundance
        filter-abund.py --threads {threads} -V {output.graph} \
            {params.prefix}.pe.keep --output {params.prefix}.pe.filter \
            >> {log} 2>&1

        # extract paired reads
        extract-paired-reads.py {params.prefix}.pe.filter \
            --output-paired {params.prefix}.dn.pe \
            --output-single {params.prefix}.dn.se >> {log} 2>&1

        # split paired reads
        split-paired-reads.py {params.prefix}.dn.pe \
            -1 {output.fastq_dn[0]} -2 {output.fastq_dn[1]} >> {log} 2>&1

        # remove fastq file
        rm $fastq
        """
