# coding: utf-8
#
#  This file is part of Sequana software
#
#  Copyright (c) 2016 - Sequana Development Team
#
#  File author(s):
#      Dimitri Desvillechabrol <dimitri.desvillechabrol@pasteur.fr>,
#          <d.desvillechabrol@gmail.com>
#
#  Distributed under the terms of the 3-clause BSD license.
#  The full license is in the LICENSE file, distributed with this software.
#
#  website: https://github.com/sequana/sequana
#  documentation: http://sequana.readthedocs.io
#
##############################################################################
"""
Author: Dimitri Desvillechabrol
Affiliation: Institut Pasteur
Aim: Variant calling
Data: paired end or single reads
Run: snakemake -s variant_calling.rules
"""
import os

import sequana
from sequana import snaketools as sm
from sequana.snaketools import SequanaConfig
sm.init("variant_calling.rules", globals())

# This must be defined before the include
configfile: "config.yaml"
manager = sm.PipelineManager("variant_calling", config)
# Clean template and replace None with empty string
config = manager.config
__snakefile__ = srcdir(__snakefile__)
__rawdata__input = manager.getrawdata()


# Get the snpeff config and create database
reference = config["bwa_mem_ref"]["reference"]
if config["snpeff"]["do"]:
    __snpeff_download_database__output = "snpEff.config"
    __snpeff_download_database__log = "common_logs/snpeff_download_database.log"
    include: sm.modules["snpeff_download_database"]
    from sequana.snpeff import SnpEff
    __snpeff_add_locus_in_fasta__config = __snpeff_download_database__output
    __snpeff_add_locus_in_fasta__fasta_input = reference
    __snpeff_add_locus_in_fasta__output = "reference/{0}".format(
        os.path.basename(reference))
    include: sm.modules["snpeff_add_locus_in_fasta"]
    __bwa_mem_ref__reference = __snpeff_add_locus_in_fasta__output
elif not os.path.isfile(reference + ".fai"):
    exec(open(sequana.modules["dynamic_copy"], "r").read())
    __copy_ref__input = reference
    __copy_ref__output = "reference/" + os.path.basename(reference)
    include: dynamic_copy("ref", manager)
    __bwa_mem_ref__reference = __copy_ref__output
else:
    __bwa_mem_ref__reference = reference

if config['input_extension'].endswith('bam') or \
    config['input_pattern'].endswith('bam'):
    __bwa_mem_ref__fai = __bwa_mem_ref__reference + ".fai"
    __bwa_mem_ref__sort_output = __rawdata__input
else:
    # Mapping with BWA MEM
    exec(open(sequana.modules["bwa_mem_dynamic"], "r").read())
    __bwa_mem_ref__input = __rawdata__input
    __bwa_mem_ref__fai = __bwa_mem_ref__reference + ".fai"
    __bwa_mem_ref__mem_output = manager.getname("bwa_mem_ref", ".bam")
    __bwa_mem_ref__sort_output = manager.getname("bwa_mem_ref", ".sorted.bam")
    __bwa_mem_ref__log = manager.getlogdir("bwa_mem_ref")
    __bwa_index_ref__log = "common_logs/bwa_index.log"
    include: bwa_mem_dynamic("ref", manager)

# Add read groups of sample for GATK
__add_read_group__input = __bwa_mem_ref__sort_output
__add_read_group__output = manager.getname("add_read_group/", ".rg.sorted.bam")
__add_read_group__log_err = manager.getlogdir("add_read_group.err")
__add_read_group__log_std = manager.getlogdir("add_read_group.std")
__add_read_group__rg = "ID=%s LB=%s PL=%s PU=%s SM=%s" % (
    manager.sample, manager.sample, manager.config.sequencing.platform,
    manager.config.sequencing.flowcell, manager.sample)
include: sm.modules["add_read_group"]

# Init all input of next rules. These rules are optional and can be inactivate
# in the config file with the "do" option.
__indel_realigner__input = __add_read_group__output
__mark_duplicates__input = __add_read_group__output
__bam_quality_filter__input = __add_read_group__output
__samtools_depth__input = __add_read_group__output
__freebayes__input = __add_read_group__output

# Indel realigner with GATK
if config["indel_realigner"]["do"]:
    __create_sequence_dictionary__reference = __bwa_mem_ref__reference
    __create_sequence_dictionary__output = __bwa_mem_ref__reference.split(
        ".fa")[0] + ".dict"
    __create_sequence_dictionary__log = "common_logs/create_sequence_dictionary.log"
    include: sm.modules["create_sequence_dictionary"]

    __indel_realigner__reference = __bwa_mem_ref__reference
    __indel_realigner__ref_dict = __create_sequence_dictionary__output
    __indel_realigner__output = manager.getname("indel_realigner",
                                                ".indel_realign.sorted.bam")
    __indel_realigner__intervals = manager.getname("indel_realigner",
                                                   ".intervals")
    __indel_realigner__log = manager.getlogdir("indel_realigner")
    include: sm.modules["indel_realigner"]
    __mark_duplicates__input = __indel_realigner__output
    __bam_quality_filter__input = __indel_realigner__output
    __freebayes__input = __indel_realigner__output
    __samtools_depth__input = __indel_realigner__output

# Mark duplicates with picard tools
if config["mark_duplicates"]["do"]:
    __mark_duplicates__output = manager.getname("mark_duplicates",
                                                ".rmdup.sorted.bam")
    __mark_duplicates__metrics = manager.getname("mark_duplicates", ".metrics")
    __mark_duplicates__log_err = manager.getlogdir("mark_duplicates.err")
    __mark_duplicates__log_std = manager.getlogdir("mark_duplicates.std")
    include: sm.modules["mark_duplicates"]
    __bam_quality_filter__input = __mark_duplicates__output
    __freebayes__input = __mark_duplicates__output
    __samtools_depth__input = __mark_duplicates__output

# bam quality filter with samtools
if config["bam_quality_filter"]["do"]:
    __bam_quality_filter__output = manager.getname("bam_quality_filter",
                                                   ".filter.sorted.bam")
    __bam_quality_filter__log = manager.getlogdir("bam_quality_filter")
    include: sm.modules["bam_quality_filter"]
    __freebayes__input = __bam_quality_filter__output
    __samtools_depth__input = [__bam_quality_filter__output,
                               __bam_quality_filter__input]

# Sequana_coverage analysis
if config["sequana_coverage"]["do"]:
    __samtools_depth__output = manager.getname("samtools_depth", ".bed")
    __samtools_depth__log = manager.getlogdir("samtools_depth")
    include: sm.modules["samtools_depth"]
    __sequana_coverage__input = __samtools_depth__output
    __sequana_coverage__fasta = __bwa_mem_ref__reference
    if config['snpeff']['do']:
        __sequana_coverage__gbk = config['snpeff']['reference']
    else:
        __sequana_coverage__gbk = []
    __sequana_coverage__output = manager.getname("sequana_coverage", ".csv")
    include: sm.modules["sequana_coverage"]
    expected_output.append(expand(__sequana_coverage__output,
                                  sample=manager.samples))

# Variant calling with Freebayes
# bai file is setup in freebayes rule for pipeline summary
__freebayes__bai = __freebayes__input + ".bai"
__freebayes__reference = __bwa_mem_ref__reference
__freebayes__output = manager.getname("freebayes", ".raw.vcf")
__freebayes__log = manager.getlogdir("freebayes")
include: sm.modules["freebayes"]

# Annotate detected variants with snpEff
if config["snpeff"]["do"]:
    __snpeff__input = __freebayes__output
    __snpeff__config = __snpeff_download_database__output
    __snpeff__output = manager.getname("snpeff", ".ann.vcf")
    __snpeff__html = manager.getname("snpeff", ".snpeff.html")
    __snpeff__log = manager.getlogdir("snpeff")
    include: sm.modules["snpeff"]
    __freebayes_vcf_filter__input = __snpeff__output
else:
    __freebayes_vcf_filter__input = __freebayes__output

# Freebayes filter
__freebayes_vcf_filter__output = manager.getname("freebayes_vcf_filter",
                                                 ".filter.vcf")
__freebayes_vcf_filter__csv = manager.getname("freebayes_vcf_filter", ".csv")
include: sm.modules["freebayes_vcf_filter"]

# Create requirements.txt(dependencies)
include: sm.modules["conda"] 

# Create rulegraph
__rulegraph__input = __snakefile__
__rulegraph__output = "rulegraph/rulegraph.svg"
__rulegraph__mapper = {"sequana_coverage":"../sequana_coverage.html",
                       "freebayes_vcf_filter":"../variant_calling.html"}
include: sm.modules["rulegraph"]
expected_output.extend(["requirements.txt", __rulegraph__output])

# create a json file that summarise information of your pipeline
# they must be complete in the onsuccess block
__summary_pipeline__inputs = __rawdata__input
__summary_pipeline__outputs = [
    __freebayes__input, __freebayes__bai, __bwa_mem_ref__reference,
    __freebayes__output, __freebayes_vcf_filter__input,
    __freebayes_vcf_filter__output]
if os.path.isfile(__bwa_mem_ref__fai):
    __summary_pipeline__outputs.append(__bwa_mem_ref__fai)
if config["snpeff"]["do"]:
    __summary_pipeline__html = [__snpeff__html]
else:
    __summary_pipeline__html = []
__summary_pipeline__rulegraph = __rulegraph__output
__summary_pipeline__requirements = "requirements.txt"
__summary_pipeline__snakefile = __snakefile__
__summary_pipeline__config = "config.yaml"
__summary_pipeline__name = "Variant Calling"
__summary_pipeline__json_output = manager.getname("summary_pipeline", ".json")
include: sm.modules["summary_pipeline"]
expected_output.append(expand(__summary_pipeline__json_output,
                              sample=manager.samples))

# these rules don't need to be submit on a node.
# snpeff_download_database needs an internet connection
localrules: snpeff_download_database, conda, rulegraph

rule pipeline_variant:
    input:
        expected_output

onsuccess:
    # add file name for snakemake stats in json
    snake_parser = snakemake.get_argument_parser().parse_args()
    json_list = expand(__summary_pipeline__json_output, sample=manager.samples)
    sm.add_stats_summary_json(json_list, snake_parser)
