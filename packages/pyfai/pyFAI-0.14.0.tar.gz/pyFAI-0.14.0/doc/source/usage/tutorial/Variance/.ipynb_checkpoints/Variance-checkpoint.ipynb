{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance of SAXS data\n",
    "\n",
    "There has been a long discussion about the validity (or not) of pixel splitting regarding the propagation of errors.\n",
    "\n",
    "## System under study\n",
    "\n",
    "Let's do a numerical experiment, simulating the following experiment:\n",
    "\n",
    "* Detector: 1024x1024 square pixels of 100Âµm each, assumed to be poissonian. \n",
    "* Geometry: The detector is placed at 1m from the sample, the beam center is in the corner of the detector\n",
    "* Sample: It is a set of spheres of Rg = 1nm, following the Guinier's law\n",
    "* Intensity: the maximum signal on the detector is 100 000 photons.\n",
    "* Wavelength: 1 Angstrom\n",
    "* During the whole studdy, the solid-angle correction will be discarded\n",
    "\n",
    "Now we define some constants for the studdy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pix = 100e-6\n",
    "shape = (1024, 1024)\n",
    "npt = 3000\n",
    "nimg = 1000\n",
    "wl = 1e-10\n",
    "I0 = 1e5\n",
    "Rg = 1.\n",
    "kwarg = {\"npt\":npt, \"method\": \"full_csr\", \"correctSolidAngle\":False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyFAI\n",
    "from pyFAI.detectors import Detector\n",
    "detector = Detector(pix, pix)\n",
    "detector.shape = detector.max_shape = shape\n",
    "print(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ai = pyFAI.AzimuthalIntegrator(dist=1, detector=detector)\n",
    "ai.wavelength = wl\n",
    "print(ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q, I = ai.integrate1d(numpy.ones(detector.shape), **kwarg)\n",
    "plot(q, I, label=\"flat_signal\")\n",
    "legend()\n",
    "xlabel(\"q ($nm^{-1}$)\")\n",
    "ylabel(\"I (count)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using Guinier law:\n",
    "q = numpy.linspace(0, 10, npt)\n",
    "I = I0* numpy.exp(-q*q*Rg*Rg/3.)\n",
    "semilogy(q, I, label=\"Guinier law\")\n",
    "xlabel(\"q ($nm^{-1}$)\")\n",
    "ylabel(\"I (count)\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reconstruction of diffusion image:\n",
    "img_theo = ai.calcfrom1d(q, I, dim1_unit=\"q_nm^-1\", correctSolidAngle=False)\n",
    "imshow(img_theo)\n",
    "#semilogy(*ai.integrate1d(img_theo, **kwarg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now construct the large dataset from poissonian statistics\n",
    "#this is slow and takes a lot of memory !\n",
    "import numpy\n",
    "dataset = numpy.empty(shape+(nimg,), dtype=numpy.int32)\n",
    "print(dataset.size/(2**20), \"MBytes\", dataset.shape)\n",
    "#this is not efficient ...\n",
    "for i in range(shape[0]):\n",
    "    for j in range(shape[1]):\n",
    "        dataset[i, j, :] = numpy.random.poisson(img_theo[i,j], nimg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_avg = dataset.mean(axis=-1)\n",
    "img_std = dataset.std(axis=-1)\n",
    "error = img_theo - img_avg\n",
    "print(\"Error max:\", abs(error.max()), \"Error mean\", abs(error.mean()))\n",
    "print(\"Deviation on variance\", abs(img_std**2-img_theo).max())\n",
    "imshow(img_std**2-img_avg)\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Few histogram of intensity\n",
    "hist(dataset[10,0,:],50)\n",
    "hist(dataset[0,10,:],50)\n",
    "hist(dataset[0,0,:],50)\n",
    "hist(dataset[20,0,:],50)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "avg = numpy.empty((nimg, npt))\n",
    "err = numpy.empty((nimg, npt))\n",
    "for i in range(nimg):\n",
    "    q,ii,e = ai.integrate1d(dataset[:, :, i], error_model=\"poisson\", **kwarg)\n",
    "    avg[i] = ii\n",
    "    err[i] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signal_avg = avg.mean(axis=0)\n",
    "error_avg = numpy.sqrt((err**2).mean(axis=0))\n",
    "errorbar(q, signal_avg, error_avg)\n",
    "yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q, signal_all, error_all = ai.integrate1d(img_avg, variance=img_std**2, **kwarg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(q, signal_avg, label=\"integrate and average\")\n",
    "plot(q, signal_all, label=\"average and integrate\")\n",
    "title(\"Signal\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(q, signal_all-signal_avg, label=\"Difference\")\n",
    "title(\"Signal\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(q, error_avg, label=\"integrate and average\")\n",
    "plot(q, error_all, label=\"average and integrate\")\n",
    "title(\"Error\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(q, error_all-error_avg, label=\"Difference\")\n",
    "title(\"Error\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(q, 100*(error_all-error_avg)/error_all, label=r\"Difference (%)\")\n",
    "title(\"Relative Error\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Comparison with no-splitting:\n",
    "kw = kwarg.copy()\n",
    "kw[\"method\"] = \"histogram\"\n",
    "kw[\"npt\"] = npt#100 #undersampling to get smth smooth\n",
    "qc, signalc, errc = ai.integrate1d(img_avg, variance=img_std**2, **kw)\n",
    "signal_nosplit = numpy.interp(q, qc, signalc)\n",
    "err_nosplit = numpy.interp(q, qc, errc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(q, 100*(err_nosplit-error_avg)/err_nosplit, label=r\"Error Difference (%)\")\n",
    "plot(q, 100*(signal_nosplit-signal_avg)/signal_nosplit, label=r\"Signal Difference (%)\")\n",
    "title(\"Split vs no-split\")\n",
    "legend()\n",
    "with_nan = 100*(err_nosplit-error_avg)/err_nosplit\n",
    "without = with_nan[numpy.isfinite(with_nan)]\n",
    "print(\"Average deviation of error (%)\",without.mean(),\"median\", numpy.median(without))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "With moderate pixels splitting (here every pixel is plit over 2/3 bins), the difference with *validated* techniques is hardly detectable and null in average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
