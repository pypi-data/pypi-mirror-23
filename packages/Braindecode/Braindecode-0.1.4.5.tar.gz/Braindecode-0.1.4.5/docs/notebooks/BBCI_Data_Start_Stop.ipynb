{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read and Decode BBCI Data with Start-Stop-Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This tutorial shows how to read and decode BBCI data with start and stop markers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup logging to see outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "log = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit more complicated than before since we ahve to add breaks etc. Here I now opt to add breaks do all preprocessings per run and only later combine them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.splitters import concatenate_sets\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne, add_breaks\n",
    "from braindecode.datasets.bbci import load_bbci_sets_from_folder\n",
    "from copy import deepcopy\n",
    "from braindecode.mne_ext.signalproc import resample_cnt, mne_apply\n",
    "from braindecode.datautil.signalproc import lowpass_cnt\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "\n",
    "def create_cnts(folder, runs, name_to_start_code, name_to_stop_code, break_start_offset_ms,\n",
    "              break_stop_offset_ms, break_start_code, break_stop_code):\n",
    "    # Load data\n",
    "    cnts = load_bbci_sets_from_folder(folder, runs)\n",
    "    \n",
    "    # Now do some preprocessings:\n",
    "    # Adding breaks, resampling to 250 Hz, lowpass below 38, eponential standardization\n",
    "    break_start_code = -1\n",
    "    break_stop_code = -2\n",
    "    \n",
    "    new_cnts = []\n",
    "    for cnt in cnts:\n",
    "        # Only take some channels \n",
    "        #cnt = cnt.drop_channels(['STI 014']) # This would remove stimulus channel\n",
    "        cnt = cnt.pick_channels(['C3', 'CPz' 'C4'])\n",
    "        # add breaks\n",
    "        new_events = add_breaks(\n",
    "            cnt.info['events'], cnt.info['sfreq'],\n",
    "            break_start_code=break_start_code, break_stop_code=break_stop_code,\n",
    "            name_to_start_codes=name_to_start_code, name_to_stop_codes=name_to_stop_code,\n",
    "            min_break_length_ms=5000, max_break_length_ms=9000)\n",
    "        n_break_start_offset = int(cnt.info['sfreq'] * break_start_offset_ms / 1000.0)\n",
    "        n_break_stop_offset = int(cnt.info['sfreq'] * break_stop_offset_ms / 1000.0)\n",
    "        # lets add some offset to break start and stop\n",
    "        new_events[new_events[:,2] == break_start_code, 0] += n_break_start_offset\n",
    "        # 0.5 sec for break stop\n",
    "        new_events[new_events[:,2] == break_stop_code, 0] +=  n_break_stop_offset\n",
    "        cnt.info['events'] = new_events\n",
    "        log.info(\"Preprocessing....\")\n",
    "        cnt = mne_apply(lambda a: lowpass_cnt(a, 38,cnt.info['sfreq'], axis=1), cnt)\n",
    "        cnt = resample_cnt(cnt, 250)\n",
    "        # mne apply will apply the function to the data (a 2d-numpy-array)\n",
    "        # have to transpose data back and forth, since\n",
    "        # exponential_running_standardize expects time x chans order\n",
    "        # while mne object has chans x time order\n",
    "        cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "            a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "            cnt)\n",
    "        new_cnts.append(cnt)\n",
    "    return new_cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 12:41:13,177 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/AnLaNBD1S001R01_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=151350\n",
      "    Range : 0 ... 151349 =      0.000 ...   605.396 secs\n",
      "Ready.\n",
      "2017-07-04 12:41:14,266 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/AnLaNBD1S001R02_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=153500\n",
      "    Range : 0 ... 153499 =      0.000 ...   613.996 secs\n",
      "Ready.\n",
      "2017-07-04 12:41:15,356 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/AnLaNBD1S001R03_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=180700\n",
      "    Range : 0 ... 180699 =      0.000 ...   722.796 secs\n",
      "Ready.\n",
      "2017-07-04 12:41:16,723 INFO : Preprocessing....\n",
      "2017-07-04 12:41:16,728 INFO : Just copying data, no resampling, since new sampling rate same.\n",
      "2017-07-04 12:41:16,822 INFO : Preprocessing....\n",
      "2017-07-04 12:41:16,827 INFO : Just copying data, no resampling, since new sampling rate same.\n",
      "2017-07-04 12:41:16,931 INFO : Preprocessing....\n",
      "2017-07-04 12:41:16,936 INFO : Just copying data, no resampling, since new sampling rate same.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "name_to_start_code = OrderedDict([('Right Hand', 1), ('Feet', 4),\n",
    "            ('Rotation', 8), ('Words', [10])])\n",
    "\n",
    "name_to_stop_code = OrderedDict([('Right Hand', [20,21,22,23,24,28,30]),\n",
    "        ('Feet', [20,21,22,23,24,28,30]),\n",
    "        ('Rotation', [20,21,22,23,24,28,30]), \n",
    "        ('Words', [20,21,22,23,24,28,30])])\n",
    "\n",
    "break_start_offset_ms = 1000\n",
    "break_stop_offset_ms = -500\n",
    "# pick some numbers that were not used before/do not exist in markers\n",
    "break_start_code = -1\n",
    "break_stop_code = -2\n",
    "train_runs = [1,2,3]\n",
    "train_cnts = create_cnts('/home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/', \n",
    "                         train_runs,\n",
    "                         name_to_start_code,\n",
    "                         name_to_stop_code, break_start_offset_ms,\n",
    "                         break_stop_offset_ms, break_start_code, break_stop_code)\n",
    "\n",
    "name_to_code_with_breaks = deepcopy(name_to_start_code)\n",
    "name_to_code_with_breaks['Break'] = break_start_code\n",
    "name_to_stop_code_with_breaks = deepcopy(name_to_stop_code)\n",
    "name_to_stop_code_with_breaks['Break'] = break_stop_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 12:41:16,994 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R09-10/AnLaNBD1S001R09_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=152050\n",
      "    Range : 0 ... 152049 =      0.000 ...   608.196 secs\n",
      "Ready.\n",
      "2017-07-04 12:41:18,075 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R09-10/AnLaNBD1S001R10_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=151100\n",
      "    Range : 0 ... 151099 =      0.000 ...   604.396 secs\n",
      "Ready.\n",
      "2017-07-04 12:41:19,260 INFO : Preprocessing....\n",
      "2017-07-04 12:41:19,264 INFO : Just copying data, no resampling, since new sampling rate same.\n",
      "2017-07-04 12:41:19,358 INFO : Preprocessing....\n",
      "2017-07-04 12:41:19,363 INFO : Just copying data, no resampling, since new sampling rate same.\n"
     ]
    }
   ],
   "source": [
    "test_runs = [9,10]\n",
    "test_cnts = create_cnts('/home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R09-10/', test_runs, name_to_start_code,\n",
    "           name_to_stop_code, break_start_offset_ms,\n",
    "              break_stop_offset_ms, break_start_code, break_stop_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already create the model now, since we need to know the receptive field size for properly cutting out the data to predict. We need to cut out data starting at -receptive_field_size samples before the first sample we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 predictions per input/trial\n",
      "Receptive field: 518/2072.00 (samples/ms)\n"
     ]
    }
   ],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds, to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 650\n",
    "in_chans = train_cnts[0].get_data().shape[0]\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=5, input_time_length=input_time_length,\n",
    "                        final_conv_length=29).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "import numpy as np\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, in_chans, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "n_receptive_field = input_time_length - n_preds_per_input\n",
    "receptive_field_ms = n_receptive_field * 1000.0 / train_cnts[0].info['sfreq']\n",
    "print(\"Receptive field: {:d}/{:.2f} (samples/ms)\".format(n_receptive_field,\n",
    "                                                      receptive_field_ms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SignalAndTarget Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 12:41:22,900 WARNING : No end marker for start marker code 1 at sample 150051 found.\n",
      "2017-07-04 12:41:22,900 INFO : Trial per class:\n",
      "Counter({'Right Hand': 29, 'Words': 21, 'Feet': 19, 'Break': 18, 'Rotation': 4})\n",
      "2017-07-04 12:41:22,903 WARNING : No end marker for start marker code 4 at sample 152701 found.\n",
      "2017-07-04 12:41:22,904 INFO : Trial per class:\n",
      "Counter({'Feet': 31, 'Words': 26, 'Break': 20, 'Right Hand': 18, 'Rotation': 6})\n",
      "2017-07-04 12:41:22,908 WARNING : No end marker for start marker code 1 at sample 179301 found.\n",
      "2017-07-04 12:41:22,909 INFO : Trial per class:\n",
      "Counter({'Feet': 38, 'Words': 29, 'Break': 23, 'Right Hand': 22, 'Rotation': 7})\n"
     ]
    }
   ],
   "source": [
    "train_sets = [create_signal_target_from_raw_mne(cnt, name_to_code_with_breaks, [-receptive_field_ms,0], \n",
    "                                         name_to_stop_code_with_breaks) for cnt in train_cnts]\n",
    "train_set = concatenate_sets(train_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 12:41:22,929 WARNING : No end marker for start marker code 4 at sample 150601 found.\n",
      "2017-07-04 12:41:22,930 INFO : Trial per class:\n",
      "Counter({'Feet': 24, 'Right Hand': 24, 'Words': 19, 'Break': 19, 'Rotation': 10})\n",
      "2017-07-04 12:41:22,933 WARNING : No end marker for start marker code 4 at sample 149601 found.\n",
      "2017-07-04 12:41:22,934 INFO : Trial per class:\n",
      "Counter({'Feet': 30, 'Right Hand': 22, 'Words': 21, 'Break': 20, 'Rotation': 8})\n"
     ]
    }
   ],
   "source": [
    "test_sets = [create_signal_target_from_raw_mne(cnt, name_to_code_with_breaks, [-receptive_field_ms,0], \n",
    "                                         name_to_stop_code_with_breaks) for cnt in test_cnts]\n",
    "test_set = concatenate_sets(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(train_set, first_set_fraction=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup optimizer and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup Monitors, Loss function, Stop Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "\n",
    "\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "\n",
    "model_constraint = None\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "stop_criterion = MaxEpochs(20)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator, loss_function, optimizer, model_constraint,\n",
    "          monitors, stop_criterion, remember_best_column='valid_misclass',\n",
    "          run_after_early_stop=True, batch_modifier=None, cuda=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 12:41:23,035 INFO : Run until first stop...\n",
      "2017-07-04 12:41:23,620 INFO : Epoch 0\n",
      "2017-07-04 12:41:23,621 INFO : train_loss                15.20389\n",
      "2017-07-04 12:41:23,622 INFO : valid_loss                16.27810\n",
      "2017-07-04 12:41:23,622 INFO : test_loss                 15.07834\n",
      "2017-07-04 12:41:23,623 INFO : train_sample_misclass     0.93548\n",
      "2017-07-04 12:41:23,623 INFO : valid_sample_misclass     0.98502\n",
      "2017-07-04 12:41:23,624 INFO : test_sample_misclass      0.91691\n",
      "2017-07-04 12:41:23,625 INFO : train_misclass            0.93976\n",
      "2017-07-04 12:41:23,625 INFO : valid_misclass            0.96774\n",
      "2017-07-04 12:41:23,626 INFO : test_misclass             0.90863\n",
      "2017-07-04 12:41:23,627 INFO : runtime                   0.00000\n",
      "2017-07-04 12:41:23,627 INFO : \n",
      "2017-07-04 12:41:23,628 INFO : New best valid_misclass: 0.967742\n",
      "2017-07-04 12:41:23,629 INFO : \n",
      "2017-07-04 12:41:24,679 INFO : Epoch 1\n",
      "2017-07-04 12:41:24,681 INFO : train_loss                1.69720\n",
      "2017-07-04 12:41:24,682 INFO : valid_loss                1.78152\n",
      "2017-07-04 12:41:24,683 INFO : test_loss                 1.74005\n",
      "2017-07-04 12:41:24,683 INFO : train_sample_misclass     0.66494\n",
      "2017-07-04 12:41:24,684 INFO : valid_sample_misclass     0.67760\n",
      "2017-07-04 12:41:24,685 INFO : test_sample_misclass      0.67506\n",
      "2017-07-04 12:41:24,686 INFO : train_misclass            0.74297\n",
      "2017-07-04 12:41:24,687 INFO : valid_misclass            0.75806\n",
      "2017-07-04 12:41:24,688 INFO : test_misclass             0.74619\n",
      "2017-07-04 12:41:24,688 INFO : runtime                   1.09826\n",
      "2017-07-04 12:41:24,689 INFO : \n",
      "2017-07-04 12:41:24,691 INFO : New best valid_misclass: 0.758065\n",
      "2017-07-04 12:41:24,692 INFO : \n",
      "2017-07-04 12:41:25,753 INFO : Epoch 2\n",
      "2017-07-04 12:41:25,754 INFO : train_loss                1.49407\n",
      "2017-07-04 12:41:25,755 INFO : valid_loss                1.61177\n",
      "2017-07-04 12:41:25,756 INFO : test_loss                 1.59951\n",
      "2017-07-04 12:41:25,756 INFO : train_sample_misclass     0.61996\n",
      "2017-07-04 12:41:25,757 INFO : valid_sample_misclass     0.62489\n",
      "2017-07-04 12:41:25,758 INFO : test_sample_misclass      0.64955\n",
      "2017-07-04 12:41:25,758 INFO : train_misclass            0.55422\n",
      "2017-07-04 12:41:25,759 INFO : valid_misclass            0.61290\n",
      "2017-07-04 12:41:25,759 INFO : test_misclass             0.64975\n",
      "2017-07-04 12:41:25,760 INFO : runtime                   1.06049\n",
      "2017-07-04 12:41:25,761 INFO : \n",
      "2017-07-04 12:41:25,762 INFO : New best valid_misclass: 0.612903\n",
      "2017-07-04 12:41:25,763 INFO : \n",
      "2017-07-04 12:41:26,831 INFO : Epoch 3\n",
      "2017-07-04 12:41:26,832 INFO : train_loss                1.79792\n",
      "2017-07-04 12:41:26,833 INFO : valid_loss                1.78341\n",
      "2017-07-04 12:41:26,833 INFO : test_loss                 1.74360\n",
      "2017-07-04 12:41:26,834 INFO : train_sample_misclass     0.68308\n",
      "2017-07-04 12:41:26,835 INFO : valid_sample_misclass     0.67709\n",
      "2017-07-04 12:41:26,835 INFO : test_sample_misclass      0.68584\n",
      "2017-07-04 12:41:26,836 INFO : train_misclass            0.70281\n",
      "2017-07-04 12:41:26,836 INFO : valid_misclass            0.77419\n",
      "2017-07-04 12:41:26,837 INFO : test_misclass             0.65990\n",
      "2017-07-04 12:41:26,838 INFO : runtime                   1.07303\n",
      "2017-07-04 12:41:26,838 INFO : \n",
      "2017-07-04 12:41:27,903 INFO : Epoch 4\n",
      "2017-07-04 12:41:27,904 INFO : train_loss                1.44074\n",
      "2017-07-04 12:41:27,905 INFO : valid_loss                1.39532\n",
      "2017-07-04 12:41:27,905 INFO : test_loss                 1.59388\n",
      "2017-07-04 12:41:27,906 INFO : train_sample_misclass     0.61166\n",
      "2017-07-04 12:41:27,907 INFO : valid_sample_misclass     0.62020\n",
      "2017-07-04 12:41:27,907 INFO : test_sample_misclass      0.65639\n",
      "2017-07-04 12:41:27,908 INFO : train_misclass            0.55823\n",
      "2017-07-04 12:41:27,909 INFO : valid_misclass            0.54839\n",
      "2017-07-04 12:41:27,909 INFO : test_misclass             0.62437\n",
      "2017-07-04 12:41:27,910 INFO : runtime                   1.07688\n",
      "2017-07-04 12:41:27,910 INFO : \n",
      "2017-07-04 12:41:27,912 INFO : New best valid_misclass: 0.548387\n",
      "2017-07-04 12:41:27,913 INFO : \n",
      "2017-07-04 12:41:28,973 INFO : Epoch 5\n",
      "2017-07-04 12:41:28,974 INFO : train_loss                1.36006\n",
      "2017-07-04 12:41:28,975 INFO : valid_loss                1.40506\n",
      "2017-07-04 12:41:28,976 INFO : test_loss                 1.48591\n",
      "2017-07-04 12:41:28,976 INFO : train_sample_misclass     0.57720\n",
      "2017-07-04 12:41:28,977 INFO : valid_sample_misclass     0.61332\n",
      "2017-07-04 12:41:28,977 INFO : test_sample_misclass      0.64040\n",
      "2017-07-04 12:41:28,978 INFO : train_misclass            0.46586\n",
      "2017-07-04 12:41:28,979 INFO : valid_misclass            0.59677\n",
      "2017-07-04 12:41:28,979 INFO : test_misclass             0.59391\n",
      "2017-07-04 12:41:28,980 INFO : runtime                   1.07038\n",
      "2017-07-04 12:41:28,981 INFO : \n",
      "2017-07-04 12:41:30,042 INFO : Epoch 6\n",
      "2017-07-04 12:41:30,043 INFO : train_loss                1.36779\n",
      "2017-07-04 12:41:30,044 INFO : valid_loss                1.38155\n",
      "2017-07-04 12:41:30,045 INFO : test_loss                 1.49083\n",
      "2017-07-04 12:41:30,045 INFO : train_sample_misclass     0.57212\n",
      "2017-07-04 12:41:30,046 INFO : valid_sample_misclass     0.62456\n",
      "2017-07-04 12:41:30,047 INFO : test_sample_misclass      0.63882\n",
      "2017-07-04 12:41:30,047 INFO : train_misclass            0.51406\n",
      "2017-07-04 12:41:30,048 INFO : valid_misclass            0.58065\n",
      "2017-07-04 12:41:30,048 INFO : test_misclass             0.61929\n",
      "2017-07-04 12:41:30,049 INFO : runtime                   1.06932\n",
      "2017-07-04 12:41:30,050 INFO : \n",
      "2017-07-04 12:41:31,113 INFO : Epoch 7\n",
      "2017-07-04 12:41:31,114 INFO : train_loss                1.40446\n",
      "2017-07-04 12:41:31,115 INFO : valid_loss                1.48456\n",
      "2017-07-04 12:41:31,116 INFO : test_loss                 1.56366\n",
      "2017-07-04 12:41:31,116 INFO : train_sample_misclass     0.59591\n",
      "2017-07-04 12:41:31,117 INFO : valid_sample_misclass     0.63399\n",
      "2017-07-04 12:41:31,118 INFO : test_sample_misclass      0.64158\n",
      "2017-07-04 12:41:31,118 INFO : train_misclass            0.64257\n",
      "2017-07-04 12:41:31,119 INFO : valid_misclass            0.74194\n",
      "2017-07-04 12:41:31,120 INFO : test_misclass             0.67513\n",
      "2017-07-04 12:41:31,120 INFO : runtime                   1.06935\n",
      "2017-07-04 12:41:31,121 INFO : \n",
      "2017-07-04 12:41:32,166 INFO : Epoch 8\n",
      "2017-07-04 12:41:32,167 INFO : train_loss                1.36714\n",
      "2017-07-04 12:41:32,168 INFO : valid_loss                1.36360\n",
      "2017-07-04 12:41:32,168 INFO : test_loss                 1.49784\n",
      "2017-07-04 12:41:32,169 INFO : train_sample_misclass     0.58281\n",
      "2017-07-04 12:41:32,170 INFO : valid_sample_misclass     0.61747\n",
      "2017-07-04 12:41:32,170 INFO : test_sample_misclass      0.64952\n",
      "2017-07-04 12:41:32,171 INFO : train_misclass            0.47791\n",
      "2017-07-04 12:41:32,171 INFO : valid_misclass            0.61290\n",
      "2017-07-04 12:41:32,172 INFO : test_misclass             0.63959\n",
      "2017-07-04 12:41:32,173 INFO : runtime                   1.06794\n",
      "2017-07-04 12:41:32,173 INFO : \n",
      "2017-07-04 12:41:33,216 INFO : Epoch 9\n",
      "2017-07-04 12:41:33,217 INFO : train_loss                1.44953\n",
      "2017-07-04 12:41:33,218 INFO : valid_loss                1.48951\n",
      "2017-07-04 12:41:33,218 INFO : test_loss                 1.70636\n",
      "2017-07-04 12:41:33,219 INFO : train_sample_misclass     0.64528\n",
      "2017-07-04 12:41:33,220 INFO : valid_sample_misclass     0.62798\n",
      "2017-07-04 12:41:33,220 INFO : test_sample_misclass      0.70055\n",
      "2017-07-04 12:41:33,221 INFO : train_misclass            0.63855\n",
      "2017-07-04 12:41:33,221 INFO : valid_misclass            0.61290\n",
      "2017-07-04 12:41:33,222 INFO : test_misclass             0.70558\n",
      "2017-07-04 12:41:33,223 INFO : runtime                   1.05058\n",
      "2017-07-04 12:41:33,223 INFO : \n",
      "2017-07-04 12:41:34,263 INFO : Epoch 10\n",
      "2017-07-04 12:41:34,264 INFO : train_loss                1.41432\n",
      "2017-07-04 12:41:34,265 INFO : valid_loss                1.42177\n",
      "2017-07-04 12:41:34,265 INFO : test_loss                 1.58715\n",
      "2017-07-04 12:41:34,266 INFO : train_sample_misclass     0.61818\n",
      "2017-07-04 12:41:34,267 INFO : valid_sample_misclass     0.64585\n",
      "2017-07-04 12:41:34,267 INFO : test_sample_misclass      0.68920\n",
      "2017-07-04 12:41:34,268 INFO : train_misclass            0.55020\n",
      "2017-07-04 12:41:34,268 INFO : valid_misclass            0.53226\n",
      "2017-07-04 12:41:34,269 INFO : test_misclass             0.68020\n",
      "2017-07-04 12:41:34,270 INFO : runtime                   1.04718\n",
      "2017-07-04 12:41:34,270 INFO : \n",
      "2017-07-04 12:41:34,272 INFO : New best valid_misclass: 0.532258\n",
      "2017-07-04 12:41:34,273 INFO : \n",
      "2017-07-04 12:41:35,328 INFO : Epoch 11\n",
      "2017-07-04 12:41:35,329 INFO : train_loss                1.36660\n",
      "2017-07-04 12:41:35,330 INFO : valid_loss                1.47960\n",
      "2017-07-04 12:41:35,331 INFO : test_loss                 1.53625\n",
      "2017-07-04 12:41:35,331 INFO : train_sample_misclass     0.59512\n",
      "2017-07-04 12:41:35,332 INFO : valid_sample_misclass     0.64746\n",
      "2017-07-04 12:41:35,333 INFO : test_sample_misclass      0.64766\n",
      "2017-07-04 12:41:35,334 INFO : train_misclass            0.59036\n",
      "2017-07-04 12:41:35,334 INFO : valid_misclass            0.74194\n",
      "2017-07-04 12:41:35,335 INFO : test_misclass             0.64467\n",
      "2017-07-04 12:41:35,336 INFO : runtime                   1.05672\n",
      "2017-07-04 12:41:35,336 INFO : \n",
      "2017-07-04 12:41:36,382 INFO : Epoch 12\n",
      "2017-07-04 12:41:36,383 INFO : train_loss                1.67790\n",
      "2017-07-04 12:41:36,383 INFO : valid_loss                1.93967\n",
      "2017-07-04 12:41:36,384 INFO : test_loss                 1.92346\n",
      "2017-07-04 12:41:36,385 INFO : train_sample_misclass     0.62820\n",
      "2017-07-04 12:41:36,385 INFO : valid_sample_misclass     0.64556\n",
      "2017-07-04 12:41:36,386 INFO : test_sample_misclass      0.65955\n",
      "2017-07-04 12:41:36,387 INFO : train_misclass            0.63454\n",
      "2017-07-04 12:41:36,387 INFO : valid_misclass            0.59677\n",
      "2017-07-04 12:41:36,388 INFO : test_misclass             0.64975\n",
      "2017-07-04 12:41:36,388 INFO : runtime                   1.06540\n",
      "2017-07-04 12:41:36,389 INFO : \n",
      "2017-07-04 12:41:37,428 INFO : Epoch 13\n",
      "2017-07-04 12:41:37,429 INFO : train_loss                1.37195\n",
      "2017-07-04 12:41:37,429 INFO : valid_loss                1.44630\n",
      "2017-07-04 12:41:37,430 INFO : test_loss                 1.47113\n",
      "2017-07-04 12:41:37,430 INFO : train_sample_misclass     0.58092\n",
      "2017-07-04 12:41:37,431 INFO : valid_sample_misclass     0.63675\n",
      "2017-07-04 12:41:37,432 INFO : test_sample_misclass      0.63087\n",
      "2017-07-04 12:41:37,432 INFO : train_misclass            0.54618\n",
      "2017-07-04 12:41:37,433 INFO : valid_misclass            0.56452\n",
      "2017-07-04 12:41:37,434 INFO : test_misclass             0.61421\n",
      "2017-07-04 12:41:37,434 INFO : runtime                   1.04633\n",
      "2017-07-04 12:41:37,435 INFO : \n",
      "2017-07-04 12:41:38,473 INFO : Epoch 14\n",
      "2017-07-04 12:41:38,474 INFO : train_loss                1.34616\n",
      "2017-07-04 12:41:38,475 INFO : valid_loss                1.41962\n",
      "2017-07-04 12:41:38,475 INFO : test_loss                 1.48592\n",
      "2017-07-04 12:41:38,476 INFO : train_sample_misclass     0.57436\n",
      "2017-07-04 12:41:38,477 INFO : valid_sample_misclass     0.64900\n",
      "2017-07-04 12:41:38,477 INFO : test_sample_misclass      0.64763\n",
      "2017-07-04 12:41:38,478 INFO : train_misclass            0.53012\n",
      "2017-07-04 12:41:38,479 INFO : valid_misclass            0.59677\n",
      "2017-07-04 12:41:38,479 INFO : test_misclass             0.63959\n",
      "2017-07-04 12:41:38,480 INFO : runtime                   1.04589\n",
      "2017-07-04 12:41:38,480 INFO : \n",
      "2017-07-04 12:41:39,521 INFO : Epoch 15\n",
      "2017-07-04 12:41:39,522 INFO : train_loss                1.36442\n",
      "2017-07-04 12:41:39,522 INFO : valid_loss                1.40570\n",
      "2017-07-04 12:41:39,523 INFO : test_loss                 1.54182\n",
      "2017-07-04 12:41:39,523 INFO : train_sample_misclass     0.58892\n",
      "2017-07-04 12:41:39,524 INFO : valid_sample_misclass     0.61711\n",
      "2017-07-04 12:41:39,525 INFO : test_sample_misclass      0.66229\n",
      "2017-07-04 12:41:39,525 INFO : train_misclass            0.53815\n",
      "2017-07-04 12:41:39,526 INFO : valid_misclass            0.59677\n",
      "2017-07-04 12:41:39,526 INFO : test_misclass             0.62437\n",
      "2017-07-04 12:41:39,527 INFO : runtime                   1.04561\n",
      "2017-07-04 12:41:39,528 INFO : \n",
      "2017-07-04 12:41:40,567 INFO : Epoch 16\n",
      "2017-07-04 12:41:40,568 INFO : train_loss                1.41771\n",
      "2017-07-04 12:41:40,569 INFO : valid_loss                1.52005\n",
      "2017-07-04 12:41:40,569 INFO : test_loss                 1.50361\n",
      "2017-07-04 12:41:40,570 INFO : train_sample_misclass     0.57512\n",
      "2017-07-04 12:41:40,570 INFO : valid_sample_misclass     0.65042\n",
      "2017-07-04 12:41:40,571 INFO : test_sample_misclass      0.63434\n",
      "2017-07-04 12:41:40,572 INFO : train_misclass            0.55823\n",
      "2017-07-04 12:41:40,572 INFO : valid_misclass            0.61290\n",
      "2017-07-04 12:41:40,573 INFO : test_misclass             0.62944\n",
      "2017-07-04 12:41:40,573 INFO : runtime                   1.04732\n",
      "2017-07-04 12:41:40,574 INFO : \n",
      "2017-07-04 12:41:41,620 INFO : Epoch 17\n",
      "2017-07-04 12:41:41,621 INFO : train_loss                1.36336\n",
      "2017-07-04 12:41:41,622 INFO : valid_loss                1.49220\n",
      "2017-07-04 12:41:41,623 INFO : test_loss                 1.57606\n",
      "2017-07-04 12:41:41,623 INFO : train_sample_misclass     0.58728\n",
      "2017-07-04 12:41:41,624 INFO : valid_sample_misclass     0.62500\n",
      "2017-07-04 12:41:41,624 INFO : test_sample_misclass      0.63364\n",
      "2017-07-04 12:41:41,625 INFO : train_misclass            0.55823\n",
      "2017-07-04 12:41:41,626 INFO : valid_misclass            0.62903\n",
      "2017-07-04 12:41:41,626 INFO : test_misclass             0.58883\n",
      "2017-07-04 12:41:41,627 INFO : runtime                   1.05214\n",
      "2017-07-04 12:41:41,627 INFO : \n",
      "2017-07-04 12:41:42,667 INFO : Epoch 18\n",
      "2017-07-04 12:41:42,668 INFO : train_loss                1.35462\n",
      "2017-07-04 12:41:42,668 INFO : valid_loss                1.46984\n",
      "2017-07-04 12:41:42,669 INFO : test_loss                 1.55309\n",
      "2017-07-04 12:41:42,670 INFO : train_sample_misclass     0.57199\n",
      "2017-07-04 12:41:42,670 INFO : valid_sample_misclass     0.61934\n",
      "2017-07-04 12:41:42,671 INFO : test_sample_misclass      0.64331\n",
      "2017-07-04 12:41:42,671 INFO : train_misclass            0.54217\n",
      "2017-07-04 12:41:42,672 INFO : valid_misclass            0.66129\n",
      "2017-07-04 12:41:42,673 INFO : test_misclass             0.64975\n",
      "2017-07-04 12:41:42,673 INFO : runtime                   1.04790\n",
      "2017-07-04 12:41:42,674 INFO : \n",
      "2017-07-04 12:41:43,712 INFO : Epoch 19\n",
      "2017-07-04 12:41:43,713 INFO : train_loss                1.38231\n",
      "2017-07-04 12:41:43,714 INFO : valid_loss                1.35009\n",
      "2017-07-04 12:41:43,715 INFO : test_loss                 1.58264\n",
      "2017-07-04 12:41:43,715 INFO : train_sample_misclass     0.58764\n",
      "2017-07-04 12:41:43,716 INFO : valid_sample_misclass     0.61257\n",
      "2017-07-04 12:41:43,716 INFO : test_sample_misclass      0.65490\n",
      "2017-07-04 12:41:43,717 INFO : train_misclass            0.51807\n",
      "2017-07-04 12:41:43,718 INFO : valid_misclass            0.58065\n",
      "2017-07-04 12:41:43,718 INFO : test_misclass             0.65482\n",
      "2017-07-04 12:41:43,719 INFO : runtime                   1.04614\n",
      "2017-07-04 12:41:43,719 INFO : \n",
      "2017-07-04 12:41:44,796 INFO : Epoch 20\n",
      "2017-07-04 12:41:44,797 INFO : train_loss                1.33498\n",
      "2017-07-04 12:41:44,797 INFO : valid_loss                1.36957\n",
      "2017-07-04 12:41:44,798 INFO : test_loss                 1.52390\n",
      "2017-07-04 12:41:44,799 INFO : train_sample_misclass     0.56833\n",
      "2017-07-04 12:41:44,799 INFO : valid_sample_misclass     0.60148\n",
      "2017-07-04 12:41:44,800 INFO : test_sample_misclass      0.64496\n",
      "2017-07-04 12:41:44,800 INFO : train_misclass            0.48594\n",
      "2017-07-04 12:41:44,801 INFO : valid_misclass            0.53226\n",
      "2017-07-04 12:41:44,802 INFO : test_misclass             0.62437\n",
      "2017-07-04 12:41:44,802 INFO : runtime                   1.05848\n",
      "2017-07-04 12:41:44,803 INFO : \n",
      "2017-07-04 12:41:44,805 INFO : New best valid_misclass: 0.532258\n",
      "2017-07-04 12:41:44,805 INFO : \n",
      "2017-07-04 12:41:44,806 INFO : Setup for second stop...\n",
      "2017-07-04 12:41:44,809 INFO : Train loss to reach 1.33498\n",
      "2017-07-04 12:41:44,810 INFO : Run until second stop...\n",
      "2017-07-04 12:41:45,449 INFO : Epoch 21\n",
      "2017-07-04 12:41:45,450 INFO : train_loss                1.34166\n",
      "2017-07-04 12:41:45,451 INFO : valid_loss                1.36957\n",
      "2017-07-04 12:41:45,451 INFO : test_loss                 1.52390\n",
      "2017-07-04 12:41:45,452 INFO : train_sample_misclass     0.57473\n",
      "2017-07-04 12:41:45,453 INFO : valid_sample_misclass     0.60148\n",
      "2017-07-04 12:41:45,453 INFO : test_sample_misclass      0.64496\n",
      "2017-07-04 12:41:45,454 INFO : train_misclass            0.49518\n",
      "2017-07-04 12:41:45,455 INFO : valid_misclass            0.53226\n",
      "2017-07-04 12:41:45,455 INFO : test_misclass             0.62437\n",
      "2017-07-04 12:41:45,456 INFO : runtime                   0.57916\n",
      "2017-07-04 12:41:45,456 INFO : \n",
      "2017-07-04 12:41:46,706 INFO : Epoch 22\n",
      "2017-07-04 12:41:46,707 INFO : train_loss                1.42720\n",
      "2017-07-04 12:41:46,708 INFO : valid_loss                1.48390\n",
      "2017-07-04 12:41:46,708 INFO : test_loss                 1.50722\n",
      "2017-07-04 12:41:46,709 INFO : train_sample_misclass     0.61033\n",
      "2017-07-04 12:41:46,710 INFO : valid_sample_misclass     0.64324\n",
      "2017-07-04 12:41:46,710 INFO : test_sample_misclass      0.64734\n",
      "2017-07-04 12:41:46,711 INFO : train_misclass            0.67203\n",
      "2017-07-04 12:41:46,711 INFO : valid_misclass            0.74194\n",
      "2017-07-04 12:41:46,712 INFO : test_misclass             0.68020\n",
      "2017-07-04 12:41:46,713 INFO : runtime                   1.27070\n",
      "2017-07-04 12:41:46,713 INFO : \n",
      "2017-07-04 12:41:47,943 INFO : Epoch 23\n",
      "2017-07-04 12:41:47,944 INFO : train_loss                1.34903\n",
      "2017-07-04 12:41:47,945 INFO : valid_loss                1.33610\n",
      "2017-07-04 12:41:47,946 INFO : test_loss                 1.45650\n",
      "2017-07-04 12:41:47,946 INFO : train_sample_misclass     0.57456\n",
      "2017-07-04 12:41:47,947 INFO : valid_sample_misclass     0.60060\n",
      "2017-07-04 12:41:47,947 INFO : test_sample_misclass      0.61710\n",
      "2017-07-04 12:41:47,948 INFO : train_misclass            0.51768\n",
      "2017-07-04 12:41:47,949 INFO : valid_misclass            0.54839\n",
      "2017-07-04 12:41:47,949 INFO : test_misclass             0.56853\n",
      "2017-07-04 12:41:47,950 INFO : runtime                   1.25017\n",
      "2017-07-04 12:41:47,950 INFO : \n",
      "2017-07-04 12:41:49,175 INFO : Epoch 24\n",
      "2017-07-04 12:41:49,176 INFO : train_loss                1.37542\n",
      "2017-07-04 12:41:49,176 INFO : valid_loss                1.38394\n",
      "2017-07-04 12:41:49,177 INFO : test_loss                 1.53010\n",
      "2017-07-04 12:41:49,178 INFO : train_sample_misclass     0.58916\n",
      "2017-07-04 12:41:49,178 INFO : valid_sample_misclass     0.62554\n",
      "2017-07-04 12:41:49,179 INFO : test_sample_misclass      0.64531\n",
      "2017-07-04 12:41:49,179 INFO : train_misclass            0.64309\n",
      "2017-07-04 12:41:49,180 INFO : valid_misclass            0.74194\n",
      "2017-07-04 12:41:49,181 INFO : test_misclass             0.69036\n",
      "2017-07-04 12:41:49,181 INFO : runtime                   1.23403\n",
      "2017-07-04 12:41:49,182 INFO : \n",
      "2017-07-04 12:41:50,411 INFO : Epoch 25\n",
      "2017-07-04 12:41:50,412 INFO : train_loss                1.38444\n",
      "2017-07-04 12:41:50,413 INFO : valid_loss                1.34930\n",
      "2017-07-04 12:41:50,413 INFO : test_loss                 1.61981\n",
      "2017-07-04 12:41:50,414 INFO : train_sample_misclass     0.59724\n",
      "2017-07-04 12:41:50,414 INFO : valid_sample_misclass     0.62047\n",
      "2017-07-04 12:41:50,415 INFO : test_sample_misclass      0.65854\n",
      "2017-07-04 12:41:50,416 INFO : train_misclass            0.52412\n",
      "2017-07-04 12:41:50,416 INFO : valid_misclass            0.56452\n",
      "2017-07-04 12:41:50,417 INFO : test_misclass             0.61929\n",
      "2017-07-04 12:41:50,418 INFO : runtime                   1.23086\n",
      "2017-07-04 12:41:50,418 INFO : \n",
      "2017-07-04 12:41:51,669 INFO : Epoch 26\n",
      "2017-07-04 12:41:51,670 INFO : train_loss                1.34393\n",
      "2017-07-04 12:41:51,671 INFO : valid_loss                1.36956\n",
      "2017-07-04 12:41:51,671 INFO : test_loss                 1.51374\n",
      "2017-07-04 12:41:51,672 INFO : train_sample_misclass     0.57105\n",
      "2017-07-04 12:41:51,673 INFO : valid_sample_misclass     0.60854\n",
      "2017-07-04 12:41:51,673 INFO : test_sample_misclass      0.65755\n",
      "2017-07-04 12:41:51,674 INFO : train_misclass            0.49196\n",
      "2017-07-04 12:41:51,675 INFO : valid_misclass            0.62903\n",
      "2017-07-04 12:41:51,675 INFO : test_misclass             0.65482\n",
      "2017-07-04 12:41:51,676 INFO : runtime                   1.23717\n",
      "2017-07-04 12:41:51,676 INFO : \n",
      "2017-07-04 12:41:52,935 INFO : Epoch 27\n",
      "2017-07-04 12:41:52,936 INFO : train_loss                1.31116\n",
      "2017-07-04 12:41:52,936 INFO : valid_loss                1.30162\n",
      "2017-07-04 12:41:52,937 INFO : test_loss                 1.49174\n",
      "2017-07-04 12:41:52,938 INFO : train_sample_misclass     0.56050\n",
      "2017-07-04 12:41:52,938 INFO : valid_sample_misclass     0.58604\n",
      "2017-07-04 12:41:52,939 INFO : test_sample_misclass      0.63830\n",
      "2017-07-04 12:41:52,939 INFO : train_misclass            0.46302\n",
      "2017-07-04 12:41:52,940 INFO : valid_misclass            0.53226\n",
      "2017-07-04 12:41:52,941 INFO : test_misclass             0.61421\n",
      "2017-07-04 12:41:52,941 INFO : runtime                   1.26563\n",
      "2017-07-04 12:41:52,942 INFO : \n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We arrive only at 38.6% accuracy. With only 3 sensors and 3 training runs, cannot expect too much great performance :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
