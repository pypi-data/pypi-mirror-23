{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read and Decode BBCI Data with Start-Stop-Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This tutorial shows how to read and decode BBCI data with start and stop markers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup logging to see outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "log = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit more complicated than before since we ahve to add breaks etc. Here I now opt to add breaks do all preprocessings per run and only later combine them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.splitters import concatenate_sets\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne, add_breaks\n",
    "from braindecode.datasets.bbci import load_bbci_sets_from_folder\n",
    "from copy import deepcopy\n",
    "from braindecode.mne_ext.signalproc import resample_cnt, mne_apply\n",
    "from braindecode.datautil.signalproc import lowpass_cnt\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "\n",
    "def create_cnts(folder, runs, name_to_start_code, name_to_stop_code, break_start_offset_ms,\n",
    "              break_stop_offset_ms, break_start_code, break_stop_code):\n",
    "    # Load data\n",
    "    cnts = load_bbci_sets_from_folder(folder, runs)\n",
    "    \n",
    "    # Now do some preprocessings:\n",
    "    # Adding breaks, resampling to 250 Hz, lowpass below 38, eponential standardization\n",
    "    break_start_code = -1\n",
    "    break_stop_code = -2\n",
    "    \n",
    "    new_cnts = []\n",
    "    for cnt in cnts:\n",
    "        # Only take some channels \n",
    "        #cnt = cnt.drop_channels(['STI 014']) # This would remove stimulus channel\n",
    "        cnt = cnt.pick_channels(['C3', 'CPz' 'C4'])\n",
    "        # add breaks\n",
    "        new_events = add_breaks(\n",
    "            cnt.info['events'], cnt.info['sfreq'],\n",
    "            break_start_code=break_start_code, break_stop_code=break_stop_code,\n",
    "            name_to_start_codes=name_to_start_code, name_to_stop_codes=name_to_stop_code,\n",
    "            min_break_length_ms=5000, max_break_length_ms=9000)\n",
    "        n_break_start_offset = int(cnt.info['sfreq'] * break_start_offset_ms / 1000.0)\n",
    "        n_break_stop_offset = int(cnt.info['sfreq'] * break_stop_offset_ms / 1000.0)\n",
    "        # lets add some offset to break start and stop\n",
    "        new_events[new_events[:,2] == break_start_code, 0] += n_break_start_offset\n",
    "        # 0.5 sec for break stop\n",
    "        new_events[new_events[:,2] == break_stop_code, 0] +=  n_break_stop_offset\n",
    "        cnt.info['events'] = new_events\n",
    "        log.info(\"Preprocessing....\")\n",
    "        cnt = mne_apply(lambda a: lowpass_cnt(a, 38,cnt.info['sfreq'], axis=1), cnt)\n",
    "        cnt = resample_cnt(cnt, 250)\n",
    "        # mne apply will apply the function to the data (a 2d-numpy-array)\n",
    "        # have to transpose data back and forth, since\n",
    "        # exponential_running_standardize expects time x chans order\n",
    "        # while mne object has chans x time order\n",
    "        cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "            a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "            cnt)\n",
    "        new_cnts.append(cnt)\n",
    "    return new_cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 12:25:35,353 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/AnLaNBD1S001R01_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=151350\n",
      "    Range : 0 ... 151349 =      0.000 ...   605.396 secs\n",
      "Ready.\n",
      "2017-07-04 12:25:36,457 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/AnLaNBD1S001R02_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=153500\n",
      "    Range : 0 ... 153499 =      0.000 ...   613.996 secs\n",
      "Ready.\n",
      "2017-07-04 12:25:37,563 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/AnLaNBD1S001R03_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=180700\n",
      "    Range : 0 ... 180699 =      0.000 ...   722.796 secs\n",
      "Ready.\n",
      "2017-07-04 12:25:38,931 INFO : Preprocessing....\n",
      "2017-07-04 12:25:38,935 INFO : Just copying data, no resampling, since new sampling rate same.\n",
      "2017-07-04 12:25:39,028 INFO : Preprocessing....\n",
      "2017-07-04 12:25:39,033 INFO : Just copying data, no resampling, since new sampling rate same.\n",
      "2017-07-04 12:25:39,138 INFO : Preprocessing....\n",
      "2017-07-04 12:25:39,143 INFO : Just copying data, no resampling, since new sampling rate same.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "name_to_start_code = OrderedDict([('Right Hand', 1), ('Feet', 4),\n",
    "            ('Rotation', 8), ('Words', [10])])\n",
    "\n",
    "name_to_stop_code = OrderedDict([('Right Hand', [20,21,22,23,24,28,30]),\n",
    "        ('Feet', [20,21,22,23,24,28,30]),\n",
    "        ('Rotation', [20,21,22,23,24,28,30]), \n",
    "        ('Words', [20,21,22,23,24,28,30])])\n",
    "\n",
    "break_start_offset_ms = 1000\n",
    "break_stop_offset_ms = -500\n",
    "# pick some numbers that were not used before/do not exist in markers\n",
    "break_start_code = -1\n",
    "break_stop_code = -2\n",
    "train_runs = [1,2,3]\n",
    "train_cnts = create_cnts('/home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/', \n",
    "                         train_runs,\n",
    "                         name_to_start_code,\n",
    "                         name_to_stop_code, break_start_offset_ms,\n",
    "                         break_stop_offset_ms, break_start_code, break_stop_code)\n",
    "\n",
    "name_to_code_with_breaks = deepcopy(name_to_start_code)\n",
    "name_to_code_with_breaks['Break'] = break_start_code\n",
    "name_to_stop_code_with_breaks = deepcopy(name_to_stop_code)\n",
    "name_to_stop_code_with_breaks['Break'] = break_stop_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 12:25:40,603 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R09-10/AnLaNBD1S001R09_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=152050\n",
      "    Range : 0 ... 152049 =      0.000 ...   608.196 secs\n",
      "Ready.\n",
      "2017-07-04 12:25:41,714 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R09-10/AnLaNBD1S001R10_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=151100\n",
      "    Range : 0 ... 151099 =      0.000 ...   604.396 secs\n",
      "Ready.\n",
      "2017-07-04 12:25:42,852 INFO : Preprocessing....\n",
      "2017-07-04 12:25:42,857 INFO : Just copying data, no resampling, since new sampling rate same.\n",
      "2017-07-04 12:25:42,950 INFO : Preprocessing....\n",
      "2017-07-04 12:25:42,954 INFO : Just copying data, no resampling, since new sampling rate same.\n"
     ]
    }
   ],
   "source": [
    "test_runs = [9,10]\n",
    "test_cnts = create_cnts('/home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R09-10/', test_runs, name_to_start_code,\n",
    "           name_to_stop_code, break_start_offset_ms,\n",
    "              break_stop_offset_ms, break_start_code, break_stop_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already create the model now, since we need to know the receptive field size for properly cutting out the data to predict. We need to cut out data starting at -receptive_field_size samples before the first sample we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 predictions per input/trial\n",
      "Receptive field: 518/2072.00 (samples/ms)\n"
     ]
    }
   ],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds, to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 650\n",
    "in_chans = train_cnts[0].get_data().shape[0]\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=5, input_time_length=input_time_length,\n",
    "                        final_conv_length=29).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "import numpy as np\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, in_chans, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "n_receptive_field = input_time_length - n_preds_per_input\n",
    "receptive_field_ms = n_receptive_field * 1000.0 / train_cnts[0].info['sfreq']\n",
    "print(\"Receptive field: {:d}/{:.2f} (samples/ms)\".format(n_receptive_field,\n",
    "                                                      receptive_field_ms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SignalAndTarget Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 12:25:43,977 WARNING : No end marker for start marker code 1 at sample 150051 found.\n",
      "2017-07-04 12:25:43,978 INFO : Trial per class:\n",
      "Counter({'Right Hand': 29, 'Words': 21, 'Feet': 19, 'Break': 18, 'Rotation': 4})\n",
      "2017-07-04 12:25:43,981 WARNING : No end marker for start marker code 4 at sample 152701 found.\n",
      "2017-07-04 12:25:43,982 INFO : Trial per class:\n",
      "Counter({'Feet': 31, 'Words': 26, 'Break': 20, 'Right Hand': 18, 'Rotation': 6})\n",
      "2017-07-04 12:25:43,986 WARNING : No end marker for start marker code 1 at sample 179301 found.\n",
      "2017-07-04 12:25:43,987 INFO : Trial per class:\n",
      "Counter({'Feet': 38, 'Words': 29, 'Break': 23, 'Right Hand': 22, 'Rotation': 7})\n"
     ]
    }
   ],
   "source": [
    "train_sets = [create_signal_target_from_raw_mne(cnt, name_to_code_with_breaks, [-receptive_field_ms,0], \n",
    "                                         name_to_stop_code_with_breaks) for cnt in train_cnts]\n",
    "train_set = concatenate_sets(train_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 12:25:44,661 WARNING : No end marker for start marker code 4 at sample 150601 found.\n",
      "2017-07-04 12:25:44,662 INFO : Trial per class:\n",
      "Counter({'Feet': 24, 'Right Hand': 24, 'Break': 19, 'Words': 19, 'Rotation': 10})\n",
      "2017-07-04 12:25:44,665 WARNING : No end marker for start marker code 4 at sample 149601 found.\n",
      "2017-07-04 12:25:44,666 INFO : Trial per class:\n",
      "Counter({'Feet': 30, 'Right Hand': 22, 'Words': 21, 'Break': 20, 'Rotation': 8})\n"
     ]
    }
   ],
   "source": [
    "test_sets = [create_signal_target_from_raw_mne(cnt, name_to_code_with_breaks, [-receptive_field_ms,0], \n",
    "                                         name_to_stop_code_with_breaks) for cnt in test_cnts]\n",
    "test_set = concatenate_sets(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(train_set, first_set_fraction=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup optimizer and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup Monitors, Loss function, Stop Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "\n",
    "\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "\n",
    "model_constraint = None\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "stop_criterion = MaxEpochs(20)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator, loss_function, optimizer, model_constraint,\n",
    "          monitors, stop_criterion, remember_best_column='valid_misclass',\n",
    "          run_after_early_stop=True, batch_modifier=None, cuda=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 12:25:57,077 INFO : Run until first stop...\n",
      "2017-07-04 12:25:57,649 INFO : Epoch 0\n",
      "2017-07-04 12:25:57,650 INFO : train_loss                15.20389\n",
      "2017-07-04 12:25:57,651 INFO : valid_loss                16.27810\n",
      "2017-07-04 12:25:57,651 INFO : test_loss                 15.07834\n",
      "2017-07-04 12:25:57,652 INFO : train_sample_misclass     0.93548\n",
      "2017-07-04 12:25:57,653 INFO : valid_sample_misclass     0.98502\n",
      "2017-07-04 12:25:57,653 INFO : test_sample_misclass      0.91691\n",
      "2017-07-04 12:25:57,654 INFO : train_misclass            0.93976\n",
      "2017-07-04 12:25:57,655 INFO : valid_misclass            0.96774\n",
      "2017-07-04 12:25:57,655 INFO : test_misclass             0.90863\n",
      "2017-07-04 12:25:57,656 INFO : runtime                   0.00000\n",
      "2017-07-04 12:25:57,656 INFO : \n",
      "2017-07-04 12:25:57,658 INFO : New best valid_misclass: 0.967742\n",
      "2017-07-04 12:25:57,658 INFO : \n",
      "2017-07-04 12:25:58,702 INFO : Epoch 1\n",
      "2017-07-04 12:25:58,703 INFO : train_loss                1.69741\n",
      "2017-07-04 12:25:58,703 INFO : valid_loss                1.78141\n",
      "2017-07-04 12:25:58,704 INFO : test_loss                 1.74019\n",
      "2017-07-04 12:25:58,705 INFO : train_sample_misclass     0.66497\n",
      "2017-07-04 12:25:58,705 INFO : valid_sample_misclass     0.67731\n",
      "2017-07-04 12:25:58,706 INFO : test_sample_misclass      0.67503\n",
      "2017-07-04 12:25:58,706 INFO : train_misclass            0.74297\n",
      "2017-07-04 12:25:58,707 INFO : valid_misclass            0.75806\n",
      "2017-07-04 12:25:58,708 INFO : test_misclass             0.74619\n",
      "2017-07-04 12:25:58,708 INFO : runtime                   1.08136\n",
      "2017-07-04 12:25:58,709 INFO : \n",
      "2017-07-04 12:25:58,711 INFO : New best valid_misclass: 0.758065\n",
      "2017-07-04 12:25:58,711 INFO : \n",
      "2017-07-04 12:25:59,750 INFO : Epoch 2\n",
      "2017-07-04 12:25:59,751 INFO : train_loss                1.49363\n",
      "2017-07-04 12:25:59,752 INFO : valid_loss                1.61131\n",
      "2017-07-04 12:25:59,753 INFO : test_loss                 1.59915\n",
      "2017-07-04 12:25:59,753 INFO : train_sample_misclass     0.61966\n",
      "2017-07-04 12:25:59,754 INFO : valid_sample_misclass     0.62510\n",
      "2017-07-04 12:25:59,755 INFO : test_sample_misclass      0.64951\n",
      "2017-07-04 12:25:59,755 INFO : train_misclass            0.55422\n",
      "2017-07-04 12:25:59,756 INFO : valid_misclass            0.61290\n",
      "2017-07-04 12:25:59,757 INFO : test_misclass             0.64975\n",
      "2017-07-04 12:25:59,757 INFO : runtime                   1.04848\n",
      "2017-07-04 12:25:59,758 INFO : \n",
      "2017-07-04 12:25:59,759 INFO : New best valid_misclass: 0.612903\n",
      "2017-07-04 12:25:59,760 INFO : \n",
      "2017-07-04 12:26:00,800 INFO : Epoch 3\n",
      "2017-07-04 12:26:00,800 INFO : train_loss                1.79879\n",
      "2017-07-04 12:26:00,801 INFO : valid_loss                1.78436\n",
      "2017-07-04 12:26:00,802 INFO : test_loss                 1.74443\n",
      "2017-07-04 12:26:00,802 INFO : train_sample_misclass     0.68326\n",
      "2017-07-04 12:26:00,803 INFO : valid_sample_misclass     0.67673\n",
      "2017-07-04 12:26:00,804 INFO : test_sample_misclass      0.68611\n",
      "2017-07-04 12:26:00,804 INFO : train_misclass            0.70281\n",
      "2017-07-04 12:26:00,805 INFO : valid_misclass            0.77419\n",
      "2017-07-04 12:26:00,806 INFO : test_misclass             0.65990\n",
      "2017-07-04 12:26:00,806 INFO : runtime                   1.04947\n",
      "2017-07-04 12:26:00,807 INFO : \n",
      "2017-07-04 12:26:01,846 INFO : Epoch 4\n",
      "2017-07-04 12:26:01,847 INFO : train_loss                1.44095\n",
      "2017-07-04 12:26:01,847 INFO : valid_loss                1.39523\n",
      "2017-07-04 12:26:01,848 INFO : test_loss                 1.59397\n",
      "2017-07-04 12:26:01,848 INFO : train_sample_misclass     0.61162\n",
      "2017-07-04 12:26:01,849 INFO : valid_sample_misclass     0.62059\n",
      "2017-07-04 12:26:01,850 INFO : test_sample_misclass      0.65660\n",
      "2017-07-04 12:26:01,850 INFO : train_misclass            0.55020\n",
      "2017-07-04 12:26:01,851 INFO : valid_misclass            0.56452\n",
      "2017-07-04 12:26:01,852 INFO : test_misclass             0.62437\n",
      "2017-07-04 12:26:01,852 INFO : runtime                   1.04472\n",
      "2017-07-04 12:26:01,853 INFO : \n",
      "2017-07-04 12:26:01,855 INFO : New best valid_misclass: 0.564516\n",
      "2017-07-04 12:26:01,855 INFO : \n",
      "2017-07-04 12:26:02,900 INFO : Epoch 5\n",
      "2017-07-04 12:26:02,901 INFO : train_loss                1.36023\n",
      "2017-07-04 12:26:02,902 INFO : valid_loss                1.40558\n",
      "2017-07-04 12:26:02,902 INFO : test_loss                 1.48631\n",
      "2017-07-04 12:26:02,903 INFO : train_sample_misclass     0.57733\n",
      "2017-07-04 12:26:02,904 INFO : valid_sample_misclass     0.61293\n",
      "2017-07-04 12:26:02,904 INFO : test_sample_misclass      0.64027\n",
      "2017-07-04 12:26:02,905 INFO : train_misclass            0.46586\n",
      "2017-07-04 12:26:02,905 INFO : valid_misclass            0.59677\n",
      "2017-07-04 12:26:02,906 INFO : test_misclass             0.59391\n",
      "2017-07-04 12:26:02,907 INFO : runtime                   1.05518\n",
      "2017-07-04 12:26:02,907 INFO : \n",
      "2017-07-04 12:26:03,949 INFO : Epoch 6\n",
      "2017-07-04 12:26:03,950 INFO : train_loss                1.36798\n",
      "2017-07-04 12:26:03,951 INFO : valid_loss                1.38181\n",
      "2017-07-04 12:26:03,951 INFO : test_loss                 1.49113\n",
      "2017-07-04 12:26:03,952 INFO : train_sample_misclass     0.57182\n",
      "2017-07-04 12:26:03,953 INFO : valid_sample_misclass     0.62509\n",
      "2017-07-04 12:26:03,953 INFO : test_sample_misclass      0.63861\n",
      "2017-07-04 12:26:03,954 INFO : train_misclass            0.51406\n",
      "2017-07-04 12:26:03,954 INFO : valid_misclass            0.58065\n",
      "2017-07-04 12:26:03,955 INFO : test_misclass             0.61929\n",
      "2017-07-04 12:26:03,956 INFO : runtime                   1.04875\n",
      "2017-07-04 12:26:03,956 INFO : \n",
      "2017-07-04 12:26:05,005 INFO : Epoch 7\n",
      "2017-07-04 12:26:05,006 INFO : train_loss                1.40419\n",
      "2017-07-04 12:26:05,006 INFO : valid_loss                1.48422\n",
      "2017-07-04 12:26:05,007 INFO : test_loss                 1.56342\n",
      "2017-07-04 12:26:05,008 INFO : train_sample_misclass     0.59615\n",
      "2017-07-04 12:26:05,008 INFO : valid_sample_misclass     0.63394\n",
      "2017-07-04 12:26:05,009 INFO : test_sample_misclass      0.64165\n",
      "2017-07-04 12:26:05,010 INFO : train_misclass            0.64257\n",
      "2017-07-04 12:26:05,010 INFO : valid_misclass            0.74194\n",
      "2017-07-04 12:26:05,011 INFO : test_misclass             0.67005\n",
      "2017-07-04 12:26:05,012 INFO : runtime                   1.05439\n",
      "2017-07-04 12:26:05,012 INFO : \n",
      "2017-07-04 12:26:06,060 INFO : Epoch 8\n",
      "2017-07-04 12:26:06,061 INFO : train_loss                1.36678\n",
      "2017-07-04 12:26:06,061 INFO : valid_loss                1.36322\n",
      "2017-07-04 12:26:06,062 INFO : test_loss                 1.49750\n",
      "2017-07-04 12:26:06,062 INFO : train_sample_misclass     0.58254\n",
      "2017-07-04 12:26:06,063 INFO : valid_sample_misclass     0.61717\n",
      "2017-07-04 12:26:06,064 INFO : test_sample_misclass      0.64910\n",
      "2017-07-04 12:26:06,064 INFO : train_misclass            0.48594\n",
      "2017-07-04 12:26:06,065 INFO : valid_misclass            0.61290\n",
      "2017-07-04 12:26:06,066 INFO : test_misclass             0.63959\n",
      "2017-07-04 12:26:06,066 INFO : runtime                   1.05449\n",
      "2017-07-04 12:26:06,067 INFO : \n",
      "2017-07-04 12:26:07,113 INFO : Epoch 9\n",
      "2017-07-04 12:26:07,114 INFO : train_loss                1.45067\n",
      "2017-07-04 12:26:07,115 INFO : valid_loss                1.49072\n",
      "2017-07-04 12:26:07,116 INFO : test_loss                 1.70817\n",
      "2017-07-04 12:26:07,116 INFO : train_sample_misclass     0.64596\n",
      "2017-07-04 12:26:07,117 INFO : valid_sample_misclass     0.62877\n",
      "2017-07-04 12:26:07,117 INFO : test_sample_misclass      0.70122\n",
      "2017-07-04 12:26:07,118 INFO : train_misclass            0.63855\n",
      "2017-07-04 12:26:07,119 INFO : valid_misclass            0.61290\n",
      "2017-07-04 12:26:07,119 INFO : test_misclass             0.70558\n",
      "2017-07-04 12:26:07,120 INFO : runtime                   1.05474\n",
      "2017-07-04 12:26:07,121 INFO : \n",
      "2017-07-04 12:26:08,171 INFO : Epoch 10\n",
      "2017-07-04 12:26:08,172 INFO : train_loss                1.41361\n",
      "2017-07-04 12:26:08,173 INFO : valid_loss                1.42107\n",
      "2017-07-04 12:26:08,173 INFO : test_loss                 1.58633\n",
      "2017-07-04 12:26:08,174 INFO : train_sample_misclass     0.61802\n",
      "2017-07-04 12:26:08,174 INFO : valid_sample_misclass     0.64580\n",
      "2017-07-04 12:26:08,175 INFO : test_sample_misclass      0.68902\n",
      "2017-07-04 12:26:08,176 INFO : train_misclass            0.55020\n",
      "2017-07-04 12:26:08,176 INFO : valid_misclass            0.53226\n",
      "2017-07-04 12:26:08,177 INFO : test_misclass             0.68020\n",
      "2017-07-04 12:26:08,178 INFO : runtime                   1.05364\n",
      "2017-07-04 12:26:08,178 INFO : \n",
      "2017-07-04 12:26:08,180 INFO : New best valid_misclass: 0.532258\n",
      "2017-07-04 12:26:08,180 INFO : \n",
      "2017-07-04 12:26:09,222 INFO : Epoch 11\n",
      "2017-07-04 12:26:09,223 INFO : train_loss                1.36610\n",
      "2017-07-04 12:26:09,224 INFO : valid_loss                1.47833\n",
      "2017-07-04 12:26:09,225 INFO : test_loss                 1.53519\n",
      "2017-07-04 12:26:09,225 INFO : train_sample_misclass     0.59448\n",
      "2017-07-04 12:26:09,226 INFO : valid_sample_misclass     0.64757\n",
      "2017-07-04 12:26:09,227 INFO : test_sample_misclass      0.64721\n",
      "2017-07-04 12:26:09,227 INFO : train_misclass            0.59036\n",
      "2017-07-04 12:26:09,228 INFO : valid_misclass            0.74194\n",
      "2017-07-04 12:26:09,229 INFO : test_misclass             0.64467\n",
      "2017-07-04 12:26:09,229 INFO : runtime                   1.05623\n",
      "2017-07-04 12:26:09,230 INFO : \n",
      "2017-07-04 12:26:10,276 INFO : Epoch 12\n",
      "2017-07-04 12:26:10,277 INFO : train_loss                1.67804\n",
      "2017-07-04 12:26:10,278 INFO : valid_loss                1.93976\n",
      "2017-07-04 12:26:10,278 INFO : test_loss                 1.92353\n",
      "2017-07-04 12:26:10,279 INFO : train_sample_misclass     0.62816\n",
      "2017-07-04 12:26:10,280 INFO : valid_sample_misclass     0.64534\n",
      "2017-07-04 12:26:10,280 INFO : test_sample_misclass      0.65945\n",
      "2017-07-04 12:26:10,281 INFO : train_misclass            0.63454\n",
      "2017-07-04 12:26:10,282 INFO : valid_misclass            0.59677\n",
      "2017-07-04 12:26:10,282 INFO : test_misclass             0.64975\n",
      "2017-07-04 12:26:10,283 INFO : runtime                   1.05080\n",
      "2017-07-04 12:26:10,284 INFO : \n",
      "2017-07-04 12:26:11,326 INFO : Epoch 13\n",
      "2017-07-04 12:26:11,327 INFO : train_loss                1.37224\n",
      "2017-07-04 12:26:11,327 INFO : valid_loss                1.44663\n",
      "2017-07-04 12:26:11,328 INFO : test_loss                 1.47154\n",
      "2017-07-04 12:26:11,328 INFO : train_sample_misclass     0.58144\n",
      "2017-07-04 12:26:11,329 INFO : valid_sample_misclass     0.63702\n",
      "2017-07-04 12:26:11,330 INFO : test_sample_misclass      0.63115\n",
      "2017-07-04 12:26:11,330 INFO : train_misclass            0.54618\n",
      "2017-07-04 12:26:11,331 INFO : valid_misclass            0.56452\n",
      "2017-07-04 12:26:11,332 INFO : test_misclass             0.61421\n",
      "2017-07-04 12:26:11,332 INFO : runtime                   1.05212\n",
      "2017-07-04 12:26:11,333 INFO : \n",
      "2017-07-04 12:26:12,378 INFO : Epoch 14\n",
      "2017-07-04 12:26:12,379 INFO : train_loss                1.34582\n",
      "2017-07-04 12:26:12,380 INFO : valid_loss                1.41950\n",
      "2017-07-04 12:26:12,380 INFO : test_loss                 1.48604\n",
      "2017-07-04 12:26:12,381 INFO : train_sample_misclass     0.57429\n",
      "2017-07-04 12:26:12,382 INFO : valid_sample_misclass     0.64906\n",
      "2017-07-04 12:26:12,382 INFO : test_sample_misclass      0.64745\n",
      "2017-07-04 12:26:12,383 INFO : train_misclass            0.53012\n",
      "2017-07-04 12:26:12,384 INFO : valid_misclass            0.59677\n",
      "2017-07-04 12:26:12,384 INFO : test_misclass             0.63959\n",
      "2017-07-04 12:26:12,385 INFO : runtime                   1.04949\n",
      "2017-07-04 12:26:12,386 INFO : \n",
      "2017-07-04 12:26:13,430 INFO : Epoch 15\n",
      "2017-07-04 12:26:13,431 INFO : train_loss                1.36491\n",
      "2017-07-04 12:26:13,431 INFO : valid_loss                1.40668\n",
      "2017-07-04 12:26:13,432 INFO : test_loss                 1.54267\n",
      "2017-07-04 12:26:13,433 INFO : train_sample_misclass     0.58961\n",
      "2017-07-04 12:26:13,433 INFO : valid_sample_misclass     0.61768\n",
      "2017-07-04 12:26:13,434 INFO : test_sample_misclass      0.66245\n",
      "2017-07-04 12:26:13,434 INFO : train_misclass            0.53815\n",
      "2017-07-04 12:26:13,435 INFO : valid_misclass            0.59677\n",
      "2017-07-04 12:26:13,436 INFO : test_misclass             0.62437\n",
      "2017-07-04 12:26:13,436 INFO : runtime                   1.05250\n",
      "2017-07-04 12:26:13,437 INFO : \n",
      "2017-07-04 12:26:14,479 INFO : Epoch 16\n",
      "2017-07-04 12:26:14,480 INFO : train_loss                1.41693\n",
      "2017-07-04 12:26:14,481 INFO : valid_loss                1.51911\n",
      "2017-07-04 12:26:14,482 INFO : test_loss                 1.50278\n",
      "2017-07-04 12:26:14,482 INFO : train_sample_misclass     0.57492\n",
      "2017-07-04 12:26:14,483 INFO : valid_sample_misclass     0.65054\n",
      "2017-07-04 12:26:14,484 INFO : test_sample_misclass      0.63392\n",
      "2017-07-04 12:26:14,484 INFO : train_misclass            0.55422\n",
      "2017-07-04 12:26:14,485 INFO : valid_misclass            0.61290\n",
      "2017-07-04 12:26:14,485 INFO : test_misclass             0.62944\n",
      "2017-07-04 12:26:14,486 INFO : runtime                   1.05149\n",
      "2017-07-04 12:26:14,487 INFO : \n",
      "2017-07-04 12:26:15,532 INFO : Epoch 17\n",
      "2017-07-04 12:26:15,533 INFO : train_loss                1.36324\n",
      "2017-07-04 12:26:15,533 INFO : valid_loss                1.49189\n",
      "2017-07-04 12:26:15,534 INFO : test_loss                 1.57587\n",
      "2017-07-04 12:26:15,535 INFO : train_sample_misclass     0.58723\n",
      "2017-07-04 12:26:15,535 INFO : valid_sample_misclass     0.62486\n",
      "2017-07-04 12:26:15,536 INFO : test_sample_misclass      0.63354\n",
      "2017-07-04 12:26:15,536 INFO : train_misclass            0.55823\n",
      "2017-07-04 12:26:15,537 INFO : valid_misclass            0.62903\n",
      "2017-07-04 12:26:15,538 INFO : test_misclass             0.58883\n",
      "2017-07-04 12:26:15,538 INFO : runtime                   1.04907\n",
      "2017-07-04 12:26:15,539 INFO : \n",
      "2017-07-04 12:26:16,583 INFO : Epoch 18\n",
      "2017-07-04 12:26:16,584 INFO : train_loss                1.35410\n",
      "2017-07-04 12:26:16,584 INFO : valid_loss                1.46889\n",
      "2017-07-04 12:26:16,585 INFO : test_loss                 1.55229\n",
      "2017-07-04 12:26:16,586 INFO : train_sample_misclass     0.57182\n",
      "2017-07-04 12:26:16,586 INFO : valid_sample_misclass     0.61910\n",
      "2017-07-04 12:26:16,587 INFO : test_sample_misclass      0.64327\n",
      "2017-07-04 12:26:16,588 INFO : train_misclass            0.54217\n",
      "2017-07-04 12:26:16,588 INFO : valid_misclass            0.66129\n",
      "2017-07-04 12:26:16,589 INFO : test_misclass             0.64975\n",
      "2017-07-04 12:26:16,589 INFO : runtime                   1.05062\n",
      "2017-07-04 12:26:16,590 INFO : \n",
      "2017-07-04 12:26:17,634 INFO : Epoch 19\n",
      "2017-07-04 12:26:17,635 INFO : train_loss                1.38215\n",
      "2017-07-04 12:26:17,636 INFO : valid_loss                1.35028\n",
      "2017-07-04 12:26:17,637 INFO : test_loss                 1.58228\n",
      "2017-07-04 12:26:17,637 INFO : train_sample_misclass     0.58790\n",
      "2017-07-04 12:26:17,638 INFO : valid_sample_misclass     0.61297\n",
      "2017-07-04 12:26:17,639 INFO : test_sample_misclass      0.65542\n",
      "2017-07-04 12:26:17,639 INFO : train_misclass            0.51807\n",
      "2017-07-04 12:26:17,640 INFO : valid_misclass            0.58065\n",
      "2017-07-04 12:26:17,641 INFO : test_misclass             0.65482\n",
      "2017-07-04 12:26:17,641 INFO : runtime                   1.05447\n",
      "2017-07-04 12:26:17,642 INFO : \n",
      "2017-07-04 12:26:18,687 INFO : Epoch 20\n",
      "2017-07-04 12:26:18,689 INFO : train_loss                1.33490\n",
      "2017-07-04 12:26:18,689 INFO : valid_loss                1.36948\n",
      "2017-07-04 12:26:18,690 INFO : test_loss                 1.52409\n",
      "2017-07-04 12:26:18,690 INFO : train_sample_misclass     0.56849\n",
      "2017-07-04 12:26:18,691 INFO : valid_sample_misclass     0.60156\n",
      "2017-07-04 12:26:18,692 INFO : test_sample_misclass      0.64502\n",
      "2017-07-04 12:26:18,692 INFO : train_misclass            0.48193\n",
      "2017-07-04 12:26:18,693 INFO : valid_misclass            0.53226\n",
      "2017-07-04 12:26:18,694 INFO : test_misclass             0.62437\n",
      "2017-07-04 12:26:18,694 INFO : runtime                   1.05152\n",
      "2017-07-04 12:26:18,695 INFO : \n",
      "2017-07-04 12:26:18,697 INFO : New best valid_misclass: 0.532258\n",
      "2017-07-04 12:26:18,697 INFO : \n",
      "2017-07-04 12:26:18,698 INFO : Setup for second stop...\n",
      "2017-07-04 12:26:18,701 INFO : Train loss to reach 1.33490\n",
      "2017-07-04 12:26:18,701 INFO : Run until second stop...\n",
      "2017-07-04 12:26:19,326 INFO : Epoch 21\n",
      "2017-07-04 12:26:19,327 INFO : train_loss                1.34157\n",
      "2017-07-04 12:26:19,327 INFO : valid_loss                1.36948\n",
      "2017-07-04 12:26:19,328 INFO : test_loss                 1.52409\n",
      "2017-07-04 12:26:19,329 INFO : train_sample_misclass     0.57488\n",
      "2017-07-04 12:26:19,329 INFO : valid_sample_misclass     0.60156\n",
      "2017-07-04 12:26:19,330 INFO : test_sample_misclass      0.64502\n",
      "2017-07-04 12:26:19,330 INFO : train_misclass            0.49196\n",
      "2017-07-04 12:26:19,331 INFO : valid_misclass            0.53226\n",
      "2017-07-04 12:26:19,332 INFO : test_misclass             0.62437\n",
      "2017-07-04 12:26:19,332 INFO : runtime                   0.56054\n",
      "2017-07-04 12:26:19,333 INFO : \n",
      "2017-07-04 12:26:20,555 INFO : Epoch 22\n",
      "2017-07-04 12:26:20,556 INFO : train_loss                1.42851\n",
      "2017-07-04 12:26:20,557 INFO : valid_loss                1.48520\n",
      "2017-07-04 12:26:20,558 INFO : test_loss                 1.50778\n",
      "2017-07-04 12:26:20,558 INFO : train_sample_misclass     0.61121\n",
      "2017-07-04 12:26:20,559 INFO : valid_sample_misclass     0.64344\n",
      "2017-07-04 12:26:20,560 INFO : test_sample_misclass      0.64764\n",
      "2017-07-04 12:26:20,560 INFO : train_misclass            0.66881\n",
      "2017-07-04 12:26:20,561 INFO : valid_misclass            0.72581\n",
      "2017-07-04 12:26:20,561 INFO : test_misclass             0.68020\n",
      "2017-07-04 12:26:20,562 INFO : runtime                   1.24445\n",
      "2017-07-04 12:26:20,563 INFO : \n",
      "2017-07-04 12:26:21,783 INFO : Epoch 23\n",
      "2017-07-04 12:26:21,784 INFO : train_loss                1.34978\n",
      "2017-07-04 12:26:21,785 INFO : valid_loss                1.33721\n",
      "2017-07-04 12:26:21,786 INFO : test_loss                 1.45695\n",
      "2017-07-04 12:26:21,786 INFO : train_sample_misclass     0.57472\n",
      "2017-07-04 12:26:21,787 INFO : valid_sample_misclass     0.60125\n",
      "2017-07-04 12:26:21,788 INFO : test_sample_misclass      0.61720\n",
      "2017-07-04 12:26:21,788 INFO : train_misclass            0.51768\n",
      "2017-07-04 12:26:21,789 INFO : valid_misclass            0.54839\n",
      "2017-07-04 12:26:21,789 INFO : test_misclass             0.57360\n",
      "2017-07-04 12:26:21,790 INFO : runtime                   1.22990\n",
      "2017-07-04 12:26:21,791 INFO : \n",
      "2017-07-04 12:26:23,011 INFO : Epoch 24\n",
      "2017-07-04 12:26:23,012 INFO : train_loss                1.37446\n",
      "2017-07-04 12:26:23,013 INFO : valid_loss                1.38296\n",
      "2017-07-04 12:26:23,014 INFO : test_loss                 1.52816\n",
      "2017-07-04 12:26:23,014 INFO : train_sample_misclass     0.58840\n",
      "2017-07-04 12:26:23,015 INFO : valid_sample_misclass     0.62516\n",
      "2017-07-04 12:26:23,015 INFO : test_sample_misclass      0.64467\n",
      "2017-07-04 12:26:23,016 INFO : train_misclass            0.63987\n",
      "2017-07-04 12:26:23,017 INFO : valid_misclass            0.74194\n",
      "2017-07-04 12:26:23,017 INFO : test_misclass             0.69036\n",
      "2017-07-04 12:26:23,018 INFO : runtime                   1.22794\n",
      "2017-07-04 12:26:23,019 INFO : \n",
      "2017-07-04 12:26:24,239 INFO : Epoch 25\n",
      "2017-07-04 12:26:24,240 INFO : train_loss                1.38385\n",
      "2017-07-04 12:26:24,240 INFO : valid_loss                1.34833\n",
      "2017-07-04 12:26:24,241 INFO : test_loss                 1.61899\n",
      "2017-07-04 12:26:24,242 INFO : train_sample_misclass     0.59691\n",
      "2017-07-04 12:26:24,242 INFO : valid_sample_misclass     0.61999\n",
      "2017-07-04 12:26:24,243 INFO : test_sample_misclass      0.65830\n",
      "2017-07-04 12:26:24,244 INFO : train_misclass            0.51768\n",
      "2017-07-04 12:26:24,244 INFO : valid_misclass            0.56452\n",
      "2017-07-04 12:26:24,245 INFO : test_misclass             0.61929\n",
      "2017-07-04 12:26:24,245 INFO : runtime                   1.22751\n",
      "2017-07-04 12:26:24,246 INFO : \n",
      "2017-07-04 12:26:25,482 INFO : Epoch 26\n",
      "2017-07-04 12:26:25,483 INFO : train_loss                1.34489\n",
      "2017-07-04 12:26:25,484 INFO : valid_loss                1.37156\n",
      "2017-07-04 12:26:25,484 INFO : test_loss                 1.51596\n",
      "2017-07-04 12:26:25,485 INFO : train_sample_misclass     0.57157\n",
      "2017-07-04 12:26:25,486 INFO : valid_sample_misclass     0.60915\n",
      "2017-07-04 12:26:25,486 INFO : test_sample_misclass      0.65838\n",
      "2017-07-04 12:26:25,487 INFO : train_misclass            0.49839\n",
      "2017-07-04 12:26:25,487 INFO : valid_misclass            0.62903\n",
      "2017-07-04 12:26:25,488 INFO : test_misclass             0.65990\n",
      "2017-07-04 12:26:25,489 INFO : runtime                   1.23249\n",
      "2017-07-04 12:26:25,489 INFO : \n",
      "2017-07-04 12:26:26,766 INFO : Epoch 27\n",
      "2017-07-04 12:26:26,767 INFO : train_loss                1.31169\n",
      "2017-07-04 12:26:26,767 INFO : valid_loss                1.30234\n",
      "2017-07-04 12:26:26,768 INFO : test_loss                 1.49263\n",
      "2017-07-04 12:26:26,769 INFO : train_sample_misclass     0.56077\n",
      "2017-07-04 12:26:26,769 INFO : valid_sample_misclass     0.58653\n",
      "2017-07-04 12:26:26,770 INFO : test_sample_misclass      0.63872\n",
      "2017-07-04 12:26:26,771 INFO : train_misclass            0.45981\n",
      "2017-07-04 12:26:26,771 INFO : valid_misclass            0.53226\n",
      "2017-07-04 12:26:26,772 INFO : test_misclass             0.61421\n",
      "2017-07-04 12:26:26,772 INFO : runtime                   1.27221\n",
      "2017-07-04 12:26:26,773 INFO : \n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only 3 sensors and 3 training runs, cannot expect too much great performance :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
