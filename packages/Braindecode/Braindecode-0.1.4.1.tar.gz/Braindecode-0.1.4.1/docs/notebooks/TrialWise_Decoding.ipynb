{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Trialwise Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this example, we will use a convolutional neural network on the [Physiobank EEG Motor Movement/Imagery Dataset](https://www.physionet.org/physiobank/database/eegmmidb/) to decode two classes:\n",
    "\n",
    "1. Executed and imagined opening and closing of both hands\n",
    "2. Executed and imagined opening and closing of both fists\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "We use only one subject (with 90 trials) in this tutorial for demonstration purposes. A more interesting decoding task with many more trials would be to do cross-subject decoding on the same dataset.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can use any way to load your EEG dataset, here we will use the [python-mne](https://www.martinos.org/mne/stable/index.html) library. For a tutorial from mne using Common Spatial Patterns to decode this data, see [here](http://martinos.org/mne/stable/auto_examples/decoding/plot_decoding_csp_eeg.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import mne\n",
    "\n",
    "physionet_paths = mne.datasets.eegbci.load_data(1, [5,6,9,10,13,14])\n",
    "\n",
    "parts = [mne.io.read_raw_edf(path, preload=True,stim_channel='auto')\n",
    "         for path in physionet_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing orphaned offset at the beginning of the file.\n",
      "179 events found\n",
      "Events id: [1 2 3]\n",
      "90 matching events found\n",
      "Loading data for 90 events and 497 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "from mne.io import concatenate_raws\n",
    "\n",
    "raw = concatenate_raws(parts)\n",
    "eeg_channel_inds = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "events = mne.find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "\n",
    "epoched = mne.Epochs(raw, events, dict(hands=2, feet=3), tmin=1, tmax=4.1, proj=False, picks=eeg_channel_inds,\n",
    "                baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Convert data to Braindecode Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Braindecode has a minimalistic ```SignalAndTarget``` class, with attributes `X` for the signal and `y` for the labels. `X` should have these dimensions: trials x channels x timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert data from volt to millivolt\n",
    "# Pytorch expects float32 for input and int64 for labels.\n",
    "X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "y = (epoched.events[:,2] - 2).astype(np.int64) #2,3 -> 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We use the first 60 trials for training and the last 30 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "\n",
    "train_set = SignalAndTarget(X[:60], y=y[:60])\n",
    "test_set = SignalAndTarget(X[60:], y=y[60:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Braindecode comes with some predefined convolutional neural network architectures for raw time-domain EEG. here, we use the shallow ConvNet model from [Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG](https://arxiv.org/abs/1703.05051)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model = ShallowFBCSPNet(in_chans=64, n_classes=2, input_time_length=train_set.X.shape[2],\n",
    "                        final_conv_length='auto').create_network()\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We use [Adam](https://arxiv.org/abs/1412.6980) to optimize the parameters of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is a conventional stochastic gradient descent training loop:\n",
    "1. Get randomly shuffled batches of trials\n",
    "2. Compute outputs, loss and gradients on the batches of trials\n",
    "3. Update your model\n",
    "4. After iterating through all batches of your dataset, report some statistics like mean accuracy and mean loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train  Loss: 1.36020\n",
      "Train  Accuracy: 46.7%\n",
      "Test   Loss: 1.08797\n",
      "Test   Accuracy: 50.0%\n",
      "Epoch 1\n",
      "Train  Loss: 0.70876\n",
      "Train  Accuracy: 68.3%\n",
      "Test   Loss: 0.78980\n",
      "Test   Accuracy: 56.7%\n",
      "Epoch 2\n",
      "Train  Loss: 0.48398\n",
      "Train  Accuracy: 75.0%\n",
      "Test   Loss: 0.73202\n",
      "Test   Accuracy: 40.0%\n",
      "Epoch 3\n",
      "Train  Loss: 0.51778\n",
      "Train  Accuracy: 75.0%\n",
      "Test   Loss: 0.77658\n",
      "Test   Accuracy: 66.7%\n",
      "Epoch 4\n",
      "Train  Loss: 0.51056\n",
      "Train  Accuracy: 70.0%\n",
      "Test   Loss: 0.75430\n",
      "Test   Accuracy: 66.7%\n",
      "Epoch 5\n",
      "Train  Loss: 0.42634\n",
      "Train  Accuracy: 85.0%\n",
      "Test   Loss: 0.67854\n",
      "Test   Accuracy: 53.3%\n",
      "Epoch 6\n",
      "Train  Loss: 0.61772\n",
      "Train  Accuracy: 70.0%\n",
      "Test   Loss: 1.01049\n",
      "Test   Accuracy: 43.3%\n",
      "Epoch 7\n",
      "Train  Loss: 0.51040\n",
      "Train  Accuracy: 75.0%\n",
      "Test   Loss: 0.93941\n",
      "Test   Accuracy: 46.7%\n",
      "Epoch 8\n",
      "Train  Loss: 0.25002\n",
      "Train  Accuracy: 95.0%\n",
      "Test   Loss: 0.66526\n",
      "Test   Accuracy: 56.7%\n",
      "Epoch 9\n",
      "Train  Loss: 0.31344\n",
      "Train  Accuracy: 88.3%\n",
      "Test   Loss: 0.74360\n",
      "Test   Accuracy: 66.7%\n",
      "Epoch 10\n",
      "Train  Loss: 0.26701\n",
      "Train  Accuracy: 88.3%\n",
      "Test   Loss: 0.69619\n",
      "Test   Accuracy: 63.3%\n",
      "Epoch 11\n",
      "Train  Loss: 0.20920\n",
      "Train  Accuracy: 95.0%\n",
      "Test   Loss: 0.64633\n",
      "Test   Accuracy: 60.0%\n",
      "Epoch 12\n",
      "Train  Loss: 0.21188\n",
      "Train  Accuracy: 93.3%\n",
      "Test   Loss: 0.71221\n",
      "Test   Accuracy: 53.3%\n",
      "Epoch 13\n",
      "Train  Loss: 0.47682\n",
      "Train  Accuracy: 78.3%\n",
      "Test   Loss: 1.23528\n",
      "Test   Accuracy: 50.0%\n",
      "Epoch 14\n",
      "Train  Loss: 0.44816\n",
      "Train  Accuracy: 80.0%\n",
      "Test   Loss: 1.31066\n",
      "Test   Accuracy: 50.0%\n",
      "Epoch 15\n",
      "Train  Loss: 0.15141\n",
      "Train  Accuracy: 95.0%\n",
      "Test   Loss: 0.80582\n",
      "Test   Accuracy: 60.0%\n",
      "Epoch 16\n",
      "Train  Loss: 0.17784\n",
      "Train  Accuracy: 91.7%\n",
      "Test   Loss: 0.69380\n",
      "Test   Accuracy: 63.3%\n",
      "Epoch 17\n",
      "Train  Loss: 0.32646\n",
      "Train  Accuracy: 80.0%\n",
      "Test   Loss: 0.86621\n",
      "Test   Accuracy: 66.7%\n",
      "Epoch 18\n",
      "Train  Loss: 0.27149\n",
      "Train  Accuracy: 86.7%\n",
      "Test   Loss: 0.84917\n",
      "Test   Accuracy: 63.3%\n",
      "Epoch 19\n",
      "Train  Loss: 0.11402\n",
      "Train  Accuracy: 96.7%\n",
      "Test   Loss: 0.73434\n",
      "Test   Accuracy: 56.7%\n",
      "Epoch 20\n",
      "Train  Loss: 0.07443\n",
      "Train  Accuracy: 100.0%\n",
      "Test   Loss: 0.80083\n",
      "Test   Accuracy: 50.0%\n",
      "Epoch 21\n",
      "Train  Loss: 0.10054\n",
      "Train  Accuracy: 96.7%\n",
      "Test   Loss: 0.96208\n",
      "Test   Accuracy: 53.3%\n",
      "Epoch 22\n",
      "Train  Loss: 0.08888\n",
      "Train  Accuracy: 98.3%\n",
      "Test   Loss: 0.89166\n",
      "Test   Accuracy: 60.0%\n",
      "Epoch 23\n",
      "Train  Loss: 0.06682\n",
      "Train  Accuracy: 98.3%\n",
      "Test   Loss: 0.77932\n",
      "Test   Accuracy: 53.3%\n",
      "Epoch 24\n",
      "Train  Loss: 0.07323\n",
      "Train  Accuracy: 100.0%\n",
      "Test   Loss: 0.73343\n",
      "Test   Accuracy: 53.3%\n",
      "Epoch 25\n",
      "Train  Loss: 0.09899\n",
      "Train  Accuracy: 98.3%\n",
      "Test   Loss: 0.74383\n",
      "Test   Accuracy: 70.0%\n",
      "Epoch 26\n",
      "Train  Loss: 0.05035\n",
      "Train  Accuracy: 100.0%\n",
      "Test   Loss: 0.75868\n",
      "Test   Accuracy: 66.7%\n",
      "Epoch 27\n",
      "Train  Loss: 0.04612\n",
      "Train  Accuracy: 100.0%\n",
      "Test   Loss: 0.87503\n",
      "Test   Accuracy: 60.0%\n",
      "Epoch 28\n",
      "Train  Loss: 0.05197\n",
      "Train  Accuracy: 100.0%\n",
      "Test   Loss: 0.88485\n",
      "Test   Accuracy: 63.3%\n",
      "Epoch 29\n",
      "Train  Loss: 0.04345\n",
      "Train  Accuracy: 100.0%\n",
      "Test   Loss: 0.86920\n",
      "Test   Accuracy: 63.3%\n"
     ]
    }
   ],
   "source": [
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from braindecode.datautil.iterators import get_balanced_batches\n",
    "import torch.nn.functional as F\n",
    "from numpy.random import RandomState\n",
    "rng = RandomState((2017,6,30))\n",
    "for i_epoch in range(30):\n",
    "    i_trials_in_batch = get_balanced_batches(len(train_set.X), rng, shuffle=True,\n",
    "                                            batch_size=30)\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    for i_trials in i_trials_in_batch:\n",
    "        # Have to add empty fourth dimension to X\n",
    "        batch_X = train_set.X[i_trials][:,:,:,None]\n",
    "        batch_y = train_set.y[i_trials]\n",
    "        net_in = np_to_var(batch_X)\n",
    "        if cuda:\n",
    "            net_in.cuda()\n",
    "        net_target = np_to_var(batch_y)\n",
    "        if cuda:\n",
    "            net_target.cuda()\n",
    "        # Remove gradients of last backward pass from all parameters \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(net_in)\n",
    "        loss = F.nll_loss(outputs, net_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print some statistics each epoch\n",
    "    model.eval()\n",
    "    print(\"Epoch {:d}\".format(i_epoch))\n",
    "    for setname, dataset in (('Train', train_set), ('Test', test_set)):\n",
    "        net_in = np_to_var(dataset.X[:,:,:,None])\n",
    "        if cuda:\n",
    "            net_in.cuda()\n",
    "        net_target = np_to_var(dataset.y)\n",
    "        if cuda:\n",
    "            net_target.cuda()\n",
    "        outputs = model(net_in)\n",
    "        loss = F.nll_loss(outputs, net_target)\n",
    "        print(\"{:6s} Loss: {:.5f}\".format(\n",
    "            setname, float(var_to_np(loss))))\n",
    "        predicted_labels = np.argmax(var_to_np(outputs), axis=1)\n",
    "        accuracy = np.mean(dataset.y  == predicted_labels)\n",
    "        print(\"{:6s} Accuracy: {:.1f}%\".format(\n",
    "            setname, accuracy * 100))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Eventually, we arrive at 63.3% accuracy, so 19 from 30 trials are correctly predicted. See in the [Cropped Decoding Tutorial](./Cropped_Decoding.html), how you can achieve higher accuracies using cropped training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dataset References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " This dataset was created and contributed to PhysioNet by the developers of the [BCI2000](http://www.schalklab.org/research/bci2000) instrumentation system, which they used in making these recordings. The system is described in:\n",
    " \n",
    "     Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. (2004) BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE TBME 51(6):1034-1043.\n",
    "\n",
    "[PhysioBank](https://physionet.org/physiobank/) is a large and growing archive of well-characterized digital recordings of physiologic signals and related data for use by the biomedical research community and further described in:\n",
    "\n",
    "    Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000) PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
