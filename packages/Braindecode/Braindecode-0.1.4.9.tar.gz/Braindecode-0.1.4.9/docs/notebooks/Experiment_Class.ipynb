{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Using the Experiment Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Braindecode provides a convenience `Experiment` class, which removes the necessity to write your own training loop. It expects a training, a validation and a test set and trains as follows:\n",
    "\n",
    "1. Train on training set until a given stop criterion is fulfilled\n",
    "2. Reset to the best epoch, i.e. reset parameters of the model and the optimizer to the state at the best epoch (\"best\" according to a given criterion) \n",
    "3. Continue training on the combined training + validation set until the loss on the validation set is as low as it was on the best epoch for the training set. (or until the ConvNet was trained twice as many epochs as the best epoch to prevent infinite training)\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "\n",
    "It is not necessary to use the Experiment class to use the remaning functionality of Braindecode. Feel free to ignore it :)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing orphaned offset at the beginning of the file.\n",
      "179 events found\n",
      "Events id: [1 2 3]\n",
      "90 matching events found\n",
      "Loading data for 90 events and 497 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from mne.io import concatenate_raws\n",
    "\n",
    "# 5,6,7,10,13,14 are codes for executed and imagined hands/feet\n",
    "subject_id = 1\n",
    "event_codes = [5,6,9,10,13,14]\n",
    "\n",
    "# This will download the files if you don't have them yet,\n",
    "# and then return the paths to the files.\n",
    "physionet_paths = mne.datasets.eegbci.load_data(subject_id, event_codes)\n",
    "\n",
    "# Load each of the files\n",
    "parts = [mne.io.read_raw_edf(path, preload=True,stim_channel='auto', verbose='WARNING')\n",
    "         for path in physionet_paths]\n",
    "\n",
    "# Concatenate them\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "# Find the events in this dataset\n",
    "events = mne.find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "\n",
    "# Use only EEG channels\n",
    "eeg_channel_inds = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "# Extract trials, only using EEG channels\n",
    "epoched = mne.Epochs(raw, events, dict(hands=2, feet=3), tmin=1, tmax=4.1, proj=False, picks=eeg_channel_inds,\n",
    "                baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Convert data to Braindecode Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "# Convert data from volt to millivolt\n",
    "# Pytorch expects float32 for input and int64 for labels.\n",
    "X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "y = (epoched.events[:,2] - 2).astype(np.int64) #2,3 -> 0,1\n",
    "\n",
    "train_set = SignalAndTarget(X[:60], y=y[:60])\n",
    "test_set = SignalAndTarget(X[60:], y=y[60:])\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(train_set, first_set_fraction=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds, to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 450\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=12).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 predictions per input/trial\n"
     ]
    }
   ],
   "source": [
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, in_chans, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to setup everything for the experiment: Iterator, loss function, monitors and stop criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "# Iterator is used to iterate over datasets both for training\n",
    "# and evaluation\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)\n",
    "\n",
    "# Loss function takes predictions as they come out of the network and the targets\n",
    "# and returns a loss\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "\n",
    "# Could be used to apply some constraint on the models, then should be object\n",
    "# with apply method that accepts a module\n",
    "model_constraint = None\n",
    "# Monitors log the training progress\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "# Stop criterion determines when the first stop happens\n",
    "stop_criterion = MaxEpochs(20)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator, loss_function, optimizer, model_constraint,\n",
    "          monitors, stop_criterion, remember_best_column='valid_misclass',\n",
    "          run_after_early_stop=True, batch_modifier=None, cuda=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-04 23:12:15,528 INFO : Run until first stop...\n",
      "2017-07-04 23:12:17,097 INFO : Epoch 0\n",
      "2017-07-04 23:12:17,100 INFO : train_loss                0.86930\n",
      "2017-07-04 23:12:17,101 INFO : valid_loss                0.74838\n",
      "2017-07-04 23:12:17,103 INFO : test_loss                 0.69756\n",
      "2017-07-04 23:12:17,104 INFO : train_sample_misclass     0.53894\n",
      "2017-07-04 23:12:17,106 INFO : valid_sample_misclass     0.47103\n",
      "2017-07-04 23:12:17,107 INFO : test_sample_misclass      0.44251\n",
      "2017-07-04 23:12:17,109 INFO : train_misclass            0.60417\n",
      "2017-07-04 23:12:17,110 INFO : valid_misclass            0.50000\n",
      "2017-07-04 23:12:17,112 INFO : test_misclass             0.40000\n",
      "2017-07-04 23:12:17,113 INFO : runtime                   0.00000\n",
      "2017-07-04 23:12:17,115 INFO : \n",
      "2017-07-04 23:12:17,117 INFO : New best valid_misclass: 0.500000\n",
      "2017-07-04 23:12:17,118 INFO : \n",
      "2017-07-04 23:12:20,980 INFO : Epoch 1\n",
      "2017-07-04 23:12:20,984 INFO : train_loss                2.33626\n",
      "2017-07-04 23:12:20,994 INFO : valid_loss                2.31771\n",
      "2017-07-04 23:12:20,996 INFO : test_loss                 2.14077\n",
      "2017-07-04 23:12:20,998 INFO : train_sample_misclass     0.48279\n",
      "2017-07-04 23:12:21,000 INFO : valid_sample_misclass     0.50000\n",
      "2017-07-04 23:12:21,001 INFO : test_sample_misclass      0.46667\n",
      "2017-07-04 23:12:21,003 INFO : train_misclass            0.50000\n",
      "2017-07-04 23:12:21,005 INFO : valid_misclass            0.50000\n",
      "2017-07-04 23:12:21,007 INFO : test_misclass             0.46667\n",
      "2017-07-04 23:12:21,009 INFO : runtime                   4.33040\n",
      "2017-07-04 23:12:21,010 INFO : \n",
      "2017-07-04 23:12:21,013 INFO : New best valid_misclass: 0.500000\n",
      "2017-07-04 23:12:21,016 INFO : \n",
      "2017-07-04 23:12:24,574 INFO : Epoch 2\n",
      "2017-07-04 23:12:24,577 INFO : train_loss                0.59815\n",
      "2017-07-04 23:12:24,579 INFO : valid_loss                0.78503\n",
      "2017-07-04 23:12:24,580 INFO : test_loss                 0.70060\n",
      "2017-07-04 23:12:24,582 INFO : train_sample_misclass     0.33918\n",
      "2017-07-04 23:12:24,583 INFO : valid_sample_misclass     0.47995\n",
      "2017-07-04 23:12:24,585 INFO : test_sample_misclass      0.41996\n",
      "2017-07-04 23:12:24,586 INFO : train_misclass            0.22917\n",
      "2017-07-04 23:12:24,588 INFO : valid_misclass            0.41667\n",
      "2017-07-04 23:12:24,590 INFO : test_misclass             0.43333\n",
      "2017-07-04 23:12:24,592 INFO : runtime                   3.52199\n",
      "2017-07-04 23:12:24,593 INFO : \n",
      "2017-07-04 23:12:24,596 INFO : New best valid_misclass: 0.416667\n",
      "2017-07-04 23:12:24,598 INFO : \n",
      "2017-07-04 23:12:28,490 INFO : Epoch 3\n",
      "2017-07-04 23:12:28,493 INFO : train_loss                0.53121\n",
      "2017-07-04 23:12:28,495 INFO : valid_loss                0.87284\n",
      "2017-07-04 23:12:28,496 INFO : test_loss                 0.69774\n",
      "2017-07-04 23:12:28,498 INFO : train_sample_misclass     0.24588\n",
      "2017-07-04 23:12:28,499 INFO : valid_sample_misclass     0.55548\n",
      "2017-07-04 23:12:28,501 INFO : test_sample_misclass      0.42709\n",
      "2017-07-04 23:12:28,502 INFO : train_misclass            0.22917\n",
      "2017-07-04 23:12:28,504 INFO : valid_misclass            0.50000\n",
      "2017-07-04 23:12:28,505 INFO : test_misclass             0.36667\n",
      "2017-07-04 23:12:28,507 INFO : runtime                   4.08024\n",
      "2017-07-04 23:12:28,508 INFO : \n",
      "2017-07-04 23:12:32,274 INFO : Epoch 4\n",
      "2017-07-04 23:12:32,277 INFO : train_loss                0.51574\n",
      "2017-07-04 23:12:32,279 INFO : valid_loss                1.10377\n",
      "2017-07-04 23:12:32,281 INFO : test_loss                 0.80095\n",
      "2017-07-04 23:12:32,282 INFO : train_sample_misclass     0.25869\n",
      "2017-07-04 23:12:32,284 INFO : valid_sample_misclass     0.60094\n",
      "2017-07-04 23:12:32,286 INFO : test_sample_misclass      0.42727\n",
      "2017-07-04 23:12:32,287 INFO : train_misclass            0.27083\n",
      "2017-07-04 23:12:32,289 INFO : valid_misclass            0.58333\n",
      "2017-07-04 23:12:32,291 INFO : test_misclass             0.46667\n",
      "2017-07-04 23:12:32,292 INFO : runtime                   3.56191\n",
      "2017-07-04 23:12:32,294 INFO : \n",
      "2017-07-04 23:12:36,090 INFO : Epoch 5\n",
      "2017-07-04 23:12:36,097 INFO : train_loss                0.52613\n",
      "2017-07-04 23:12:36,101 INFO : valid_loss                1.22322\n",
      "2017-07-04 23:12:36,102 INFO : test_loss                 0.86285\n",
      "2017-07-04 23:12:36,103 INFO : train_sample_misclass     0.27635\n",
      "2017-07-04 23:12:36,104 INFO : valid_sample_misclass     0.58445\n",
      "2017-07-04 23:12:36,105 INFO : test_sample_misclass      0.43841\n",
      "2017-07-04 23:12:36,106 INFO : train_misclass            0.33333\n",
      "2017-07-04 23:12:36,106 INFO : valid_misclass            0.58333\n",
      "2017-07-04 23:12:36,107 INFO : test_misclass             0.46667\n",
      "2017-07-04 23:12:36,108 INFO : runtime                   3.89917\n",
      "2017-07-04 23:12:36,109 INFO : \n",
      "2017-07-04 23:12:39,259 INFO : Epoch 6\n",
      "2017-07-04 23:12:39,269 INFO : train_loss                0.54906\n",
      "2017-07-04 23:12:39,271 INFO : valid_loss                1.23573\n",
      "2017-07-04 23:12:39,272 INFO : test_loss                 0.92210\n",
      "2017-07-04 23:12:39,274 INFO : train_sample_misclass     0.28816\n",
      "2017-07-04 23:12:39,276 INFO : valid_sample_misclass     0.53810\n",
      "2017-07-04 23:12:39,277 INFO : test_sample_misclass      0.45205\n",
      "2017-07-04 23:12:39,279 INFO : train_misclass            0.33333\n",
      "2017-07-04 23:12:39,281 INFO : valid_misclass            0.58333\n",
      "2017-07-04 23:12:39,282 INFO : test_misclass             0.46667\n",
      "2017-07-04 23:12:39,284 INFO : runtime                   3.36125\n",
      "2017-07-04 23:12:39,286 INFO : \n",
      "2017-07-04 23:12:42,376 INFO : Epoch 7\n",
      "2017-07-04 23:12:42,384 INFO : train_loss                0.59627\n",
      "2017-07-04 23:12:42,386 INFO : valid_loss                1.16602\n",
      "2017-07-04 23:12:42,388 INFO : test_loss                 0.95655\n",
      "2017-07-04 23:12:42,390 INFO : train_sample_misclass     0.32253\n",
      "2017-07-04 23:12:42,391 INFO : valid_sample_misclass     0.53053\n",
      "2017-07-04 23:12:42,394 INFO : test_sample_misclass      0.46346\n",
      "2017-07-04 23:12:42,395 INFO : train_misclass            0.37500\n",
      "2017-07-04 23:12:42,397 INFO : valid_misclass            0.58333\n",
      "2017-07-04 23:12:42,399 INFO : test_misclass             0.46667\n",
      "2017-07-04 23:12:42,400 INFO : runtime                   3.21394\n",
      "2017-07-04 23:12:42,402 INFO : \n",
      "2017-07-04 23:12:45,476 INFO : Epoch 8\n",
      "2017-07-04 23:12:45,483 INFO : train_loss                0.40527\n",
      "2017-07-04 23:12:45,485 INFO : valid_loss                0.95821\n",
      "2017-07-04 23:12:45,486 INFO : test_loss                 0.79267\n",
      "2017-07-04 23:12:45,488 INFO : train_sample_misclass     0.19112\n",
      "2017-07-04 23:12:45,489 INFO : valid_sample_misclass     0.52607\n",
      "2017-07-04 23:12:45,491 INFO : test_sample_misclass      0.43351\n",
      "2017-07-04 23:12:45,493 INFO : train_misclass            0.16667\n",
      "2017-07-04 23:12:45,494 INFO : valid_misclass            0.58333\n",
      "2017-07-04 23:12:45,496 INFO : test_misclass             0.40000\n",
      "2017-07-04 23:12:45,498 INFO : runtime                   3.01966\n",
      "2017-07-04 23:12:45,499 INFO : \n",
      "2017-07-04 23:12:48,463 INFO : Epoch 9\n",
      "2017-07-04 23:12:48,465 INFO : train_loss                0.30290\n",
      "2017-07-04 23:12:48,466 INFO : valid_loss                0.89596\n",
      "2017-07-04 23:12:48,468 INFO : test_loss                 0.75205\n",
      "2017-07-04 23:12:48,469 INFO : train_sample_misclass     0.10968\n",
      "2017-07-04 23:12:48,471 INFO : valid_sample_misclass     0.56684\n",
      "2017-07-04 23:12:48,472 INFO : test_sample_misclass      0.43119\n",
      "2017-07-04 23:12:48,474 INFO : train_misclass            0.08333\n",
      "2017-07-04 23:12:48,475 INFO : valid_misclass            0.58333\n",
      "2017-07-04 23:12:48,477 INFO : test_misclass             0.36667\n",
      "2017-07-04 23:12:48,478 INFO : runtime                   3.09004\n",
      "2017-07-04 23:12:48,480 INFO : \n",
      "2017-07-04 23:12:51,843 INFO : Epoch 10\n",
      "2017-07-04 23:12:51,851 INFO : train_loss                0.25623\n",
      "2017-07-04 23:12:51,853 INFO : valid_loss                0.89555\n",
      "2017-07-04 23:12:51,854 INFO : test_loss                 0.75208\n",
      "2017-07-04 23:12:51,856 INFO : train_sample_misclass     0.06088\n",
      "2017-07-04 23:12:51,858 INFO : valid_sample_misclass     0.55637\n",
      "2017-07-04 23:12:51,859 INFO : test_sample_misclass      0.41765\n",
      "2017-07-04 23:12:51,861 INFO : train_misclass            0.02083\n",
      "2017-07-04 23:12:51,863 INFO : valid_misclass            0.58333\n",
      "2017-07-04 23:12:51,864 INFO : test_misclass             0.33333\n",
      "2017-07-04 23:12:51,866 INFO : runtime                   3.23385\n",
      "2017-07-04 23:12:51,868 INFO : \n",
      "2017-07-04 23:12:55,065 INFO : Epoch 11\n",
      "2017-07-04 23:12:55,072 INFO : train_loss                0.24021\n",
      "2017-07-04 23:12:55,074 INFO : valid_loss                0.90581\n",
      "2017-07-04 23:12:55,076 INFO : test_loss                 0.75648\n",
      "2017-07-04 23:12:55,078 INFO : train_sample_misclass     0.06205\n",
      "2017-07-04 23:12:55,079 INFO : valid_sample_misclass     0.54256\n",
      "2017-07-04 23:12:55,081 INFO : test_sample_misclass      0.39804\n",
      "2017-07-04 23:12:55,083 INFO : train_misclass            0.02083\n",
      "2017-07-04 23:12:55,084 INFO : valid_misclass            0.58333\n",
      "2017-07-04 23:12:55,086 INFO : test_misclass             0.33333\n",
      "2017-07-04 23:12:55,088 INFO : runtime                   3.19742\n",
      "2017-07-04 23:12:55,089 INFO : \n",
      "2017-07-04 23:12:58,458 INFO : Epoch 12\n",
      "2017-07-04 23:12:58,466 INFO : train_loss                0.20491\n",
      "2017-07-04 23:12:58,468 INFO : valid_loss                0.90257\n",
      "2017-07-04 23:12:58,469 INFO : test_loss                 0.75600\n",
      "2017-07-04 23:12:58,471 INFO : train_sample_misclass     0.05041\n",
      "2017-07-04 23:12:58,473 INFO : valid_sample_misclass     0.54055\n",
      "2017-07-04 23:12:58,474 INFO : test_sample_misclass      0.39501\n",
      "2017-07-04 23:12:58,476 INFO : train_misclass            0.00000\n",
      "2017-07-04 23:12:58,478 INFO : valid_misclass            0.58333\n",
      "2017-07-04 23:12:58,479 INFO : test_misclass             0.33333\n",
      "2017-07-04 23:12:58,481 INFO : runtime                   3.21470\n",
      "2017-07-04 23:12:58,483 INFO : \n",
      "2017-07-04 23:13:01,690 INFO : Epoch 13\n",
      "2017-07-04 23:13:01,699 INFO : train_loss                0.17244\n",
      "2017-07-04 23:13:01,701 INFO : valid_loss                0.90562\n",
      "2017-07-04 23:13:01,703 INFO : test_loss                 0.76539\n",
      "2017-07-04 23:13:01,704 INFO : train_sample_misclass     0.03793\n",
      "2017-07-04 23:13:01,706 INFO : valid_sample_misclass     0.56194\n",
      "2017-07-04 23:13:01,708 INFO : test_sample_misclass      0.38752\n",
      "2017-07-04 23:13:01,710 INFO : train_misclass            0.00000\n",
      "2017-07-04 23:13:01,711 INFO : valid_misclass            0.66667\n",
      "2017-07-04 23:13:01,713 INFO : test_misclass             0.36667\n",
      "2017-07-04 23:13:01,715 INFO : runtime                   3.30130\n",
      "2017-07-04 23:13:01,717 INFO : \n",
      "2017-07-04 23:13:04,968 INFO : Epoch 14\n",
      "2017-07-04 23:13:04,981 INFO : train_loss                0.15207\n",
      "2017-07-04 23:13:04,983 INFO : valid_loss                0.90600\n",
      "2017-07-04 23:13:04,985 INFO : test_loss                 0.76428\n",
      "2017-07-04 23:13:04,987 INFO : train_sample_misclass     0.02969\n",
      "2017-07-04 23:13:04,988 INFO : valid_sample_misclass     0.54924\n",
      "2017-07-04 23:13:04,990 INFO : test_sample_misclass      0.36551\n",
      "2017-07-04 23:13:04,992 INFO : train_misclass            0.00000\n",
      "2017-07-04 23:13:04,993 INFO : valid_misclass            0.58333\n",
      "2017-07-04 23:13:04,995 INFO : test_misclass             0.36667\n",
      "2017-07-04 23:13:04,997 INFO : runtime                   3.47310\n",
      "2017-07-04 23:13:04,999 INFO : \n",
      "2017-07-04 23:13:08,292 INFO : Epoch 15\n",
      "2017-07-04 23:13:08,294 INFO : train_loss                0.14998\n",
      "2017-07-04 23:13:08,296 INFO : valid_loss                0.96411\n",
      "2017-07-04 23:13:08,297 INFO : test_loss                 0.81256\n",
      "2017-07-04 23:13:08,299 INFO : train_sample_misclass     0.04027\n",
      "2017-07-04 23:13:08,300 INFO : valid_sample_misclass     0.48061\n",
      "2017-07-04 23:13:08,302 INFO : test_sample_misclass      0.35811\n",
      "2017-07-04 23:13:08,303 INFO : train_misclass            0.02083\n",
      "2017-07-04 23:13:08,305 INFO : valid_misclass            0.50000\n",
      "2017-07-04 23:13:08,306 INFO : test_misclass             0.33333\n",
      "2017-07-04 23:13:08,308 INFO : runtime                   3.36223\n",
      "2017-07-04 23:13:08,310 INFO : \n",
      "2017-07-04 23:13:11,310 INFO : Epoch 16\n",
      "2017-07-04 23:13:11,311 INFO : train_loss                0.10915\n",
      "2017-07-04 23:13:11,312 INFO : valid_loss                0.91490\n",
      "2017-07-04 23:13:11,313 INFO : test_loss                 0.80608\n",
      "2017-07-04 23:13:11,313 INFO : train_sample_misclass     0.01588\n",
      "2017-07-04 23:13:11,314 INFO : valid_sample_misclass     0.54234\n",
      "2017-07-04 23:13:11,315 INFO : test_sample_misclass      0.34537\n",
      "2017-07-04 23:13:11,315 INFO : train_misclass            0.00000\n",
      "2017-07-04 23:13:11,316 INFO : valid_misclass            0.33333\n",
      "2017-07-04 23:13:11,317 INFO : test_misclass             0.33333\n",
      "2017-07-04 23:13:11,317 INFO : runtime                   3.23558\n",
      "2017-07-04 23:13:11,318 INFO : \n",
      "2017-07-04 23:13:11,320 INFO : New best valid_misclass: 0.333333\n",
      "2017-07-04 23:13:11,320 INFO : \n",
      "2017-07-04 23:13:13,101 INFO : Epoch 17\n",
      "2017-07-04 23:13:13,104 INFO : train_loss                0.15003\n",
      "2017-07-04 23:13:13,105 INFO : valid_loss                0.91323\n",
      "2017-07-04 23:13:13,107 INFO : test_loss                 0.81002\n",
      "2017-07-04 23:13:13,108 INFO : train_sample_misclass     0.05403\n",
      "2017-07-04 23:13:13,110 INFO : valid_sample_misclass     0.51337\n",
      "2017-07-04 23:13:13,112 INFO : test_sample_misclass      0.34403\n",
      "2017-07-04 23:13:13,113 INFO : train_misclass            0.04167\n",
      "2017-07-04 23:13:13,115 INFO : valid_misclass            0.50000\n",
      "2017-07-04 23:13:13,116 INFO : test_misclass             0.23333\n",
      "2017-07-04 23:13:13,119 INFO : runtime                   2.03534\n",
      "2017-07-04 23:13:13,120 INFO : \n",
      "2017-07-04 23:13:14,832 INFO : Epoch 18\n",
      "2017-07-04 23:13:14,835 INFO : train_loss                0.09315\n",
      "2017-07-04 23:13:14,836 INFO : valid_loss                0.89064\n",
      "2017-07-04 23:13:14,838 INFO : test_loss                 0.77360\n",
      "2017-07-04 23:13:14,839 INFO : train_sample_misclass     0.01025\n",
      "2017-07-04 23:13:14,841 INFO : valid_sample_misclass     0.49666\n",
      "2017-07-04 23:13:14,842 INFO : test_sample_misclass      0.30873\n",
      "2017-07-04 23:13:14,844 INFO : train_misclass            0.00000\n",
      "2017-07-04 23:13:14,845 INFO : valid_misclass            0.33333\n",
      "2017-07-04 23:13:14,847 INFO : test_misclass             0.33333\n",
      "2017-07-04 23:13:14,848 INFO : runtime                   1.65685\n",
      "2017-07-04 23:13:14,850 INFO : \n",
      "2017-07-04 23:13:14,852 INFO : New best valid_misclass: 0.333333\n",
      "2017-07-04 23:13:14,854 INFO : \n",
      "2017-07-04 23:13:16,531 INFO : Epoch 19\n",
      "2017-07-04 23:13:16,534 INFO : train_loss                0.09407\n",
      "2017-07-04 23:13:16,535 INFO : valid_loss                0.96350\n",
      "2017-07-04 23:13:16,537 INFO : test_loss                 0.84831\n",
      "2017-07-04 23:13:16,538 INFO : train_sample_misclass     0.02078\n",
      "2017-07-04 23:13:16,540 INFO : valid_sample_misclass     0.49042\n",
      "2017-07-04 23:13:16,541 INFO : test_sample_misclass      0.33137\n",
      "2017-07-04 23:13:16,543 INFO : train_misclass            0.00000\n",
      "2017-07-04 23:13:16,545 INFO : valid_misclass            0.50000\n",
      "2017-07-04 23:13:16,546 INFO : test_misclass             0.30000\n",
      "2017-07-04 23:13:16,548 INFO : runtime                   1.70843\n",
      "2017-07-04 23:13:16,549 INFO : \n",
      "2017-07-04 23:13:18,156 INFO : Epoch 20\n",
      "2017-07-04 23:13:18,158 INFO : train_loss                0.06822\n",
      "2017-07-04 23:13:18,160 INFO : valid_loss                1.05598\n",
      "2017-07-04 23:13:18,161 INFO : test_loss                 0.88760\n",
      "2017-07-04 23:13:18,163 INFO : train_sample_misclass     0.00847\n",
      "2017-07-04 23:13:18,164 INFO : valid_sample_misclass     0.51448\n",
      "2017-07-04 23:13:18,166 INFO : test_sample_misclass      0.33066\n",
      "2017-07-04 23:13:18,167 INFO : train_misclass            0.00000\n",
      "2017-07-04 23:13:18,169 INFO : valid_misclass            0.50000\n",
      "2017-07-04 23:13:18,170 INFO : test_misclass             0.36667\n",
      "2017-07-04 23:13:18,172 INFO : runtime                   1.69522\n",
      "2017-07-04 23:13:18,173 INFO : \n",
      "2017-07-04 23:13:18,175 INFO : Setup for second stop...\n",
      "2017-07-04 23:13:18,179 INFO : Train loss to reach 0.09315\n",
      "2017-07-04 23:13:18,180 INFO : Run until second stop...\n",
      "2017-07-04 23:13:18,556 INFO : Epoch 19\n",
      "2017-07-04 23:13:18,558 INFO : train_loss                0.25265\n",
      "2017-07-04 23:13:18,560 INFO : valid_loss                0.89064\n",
      "2017-07-04 23:13:18,561 INFO : test_loss                 0.77360\n",
      "2017-07-04 23:13:18,563 INFO : train_sample_misclass     0.10753\n",
      "2017-07-04 23:13:18,564 INFO : valid_sample_misclass     0.49666\n",
      "2017-07-04 23:13:18,566 INFO : test_sample_misclass      0.30873\n",
      "2017-07-04 23:13:18,567 INFO : train_misclass            0.06667\n",
      "2017-07-04 23:13:18,569 INFO : valid_misclass            0.33333\n",
      "2017-07-04 23:13:18,570 INFO : test_misclass             0.33333\n",
      "2017-07-04 23:13:18,572 INFO : runtime                   0.46055\n",
      "2017-07-04 23:13:18,573 INFO : \n",
      "2017-07-04 23:13:21,087 INFO : Epoch 20\n",
      "2017-07-04 23:13:21,089 INFO : train_loss                0.21080\n",
      "2017-07-04 23:13:21,091 INFO : valid_loss                0.68103\n",
      "2017-07-04 23:13:21,092 INFO : test_loss                 0.73508\n",
      "2017-07-04 23:13:21,094 INFO : train_sample_misclass     0.08324\n",
      "2017-07-04 23:13:21,095 INFO : valid_sample_misclass     0.34915\n",
      "2017-07-04 23:13:21,097 INFO : test_sample_misclass      0.31025\n",
      "2017-07-04 23:13:21,098 INFO : train_misclass            0.10000\n",
      "2017-07-04 23:13:21,099 INFO : valid_misclass            0.50000\n",
      "2017-07-04 23:13:21,101 INFO : test_misclass             0.26667\n",
      "2017-07-04 23:13:21,103 INFO : runtime                   2.39440\n",
      "2017-07-04 23:13:21,104 INFO : \n",
      "2017-07-04 23:13:23,284 INFO : Epoch 21\n",
      "2017-07-04 23:13:23,287 INFO : train_loss                0.18816\n",
      "2017-07-04 23:13:23,288 INFO : valid_loss                0.46174\n",
      "2017-07-04 23:13:23,290 INFO : test_loss                 0.66965\n",
      "2017-07-04 23:13:23,291 INFO : train_sample_misclass     0.07406\n",
      "2017-07-04 23:13:23,293 INFO : valid_sample_misclass     0.24643\n",
      "2017-07-04 23:13:23,294 INFO : test_sample_misclass      0.28066\n",
      "2017-07-04 23:13:23,296 INFO : train_misclass            0.05000\n",
      "2017-07-04 23:13:23,297 INFO : valid_misclass            0.16667\n",
      "2017-07-04 23:13:23,299 INFO : test_misclass             0.26667\n",
      "2017-07-04 23:13:23,300 INFO : runtime                   2.22937\n",
      "2017-07-04 23:13:23,302 INFO : \n",
      "2017-07-04 23:13:25,074 INFO : Epoch 22\n",
      "2017-07-04 23:13:25,076 INFO : train_loss                0.13663\n",
      "2017-07-04 23:13:25,078 INFO : valid_loss                0.28806\n",
      "2017-07-04 23:13:25,079 INFO : test_loss                 0.63335\n",
      "2017-07-04 23:13:25,081 INFO : train_sample_misclass     0.02567\n",
      "2017-07-04 23:13:25,082 INFO : valid_sample_misclass     0.06796\n",
      "2017-07-04 23:13:25,084 INFO : test_sample_misclass      0.25677\n",
      "2017-07-04 23:13:25,086 INFO : train_misclass            0.00000\n",
      "2017-07-04 23:13:25,087 INFO : valid_misclass            0.00000\n",
      "2017-07-04 23:13:25,089 INFO : test_misclass             0.23333\n",
      "2017-07-04 23:13:25,090 INFO : runtime                   1.78031\n",
      "2017-07-04 23:13:25,092 INFO : \n",
      "2017-07-04 23:13:27,228 INFO : Epoch 23\n",
      "2017-07-04 23:13:27,231 INFO : train_loss                0.18469\n",
      "2017-07-04 23:13:27,232 INFO : valid_loss                0.33505\n",
      "2017-07-04 23:13:27,234 INFO : test_loss                 0.74569\n",
      "2017-07-04 23:13:27,235 INFO : train_sample_misclass     0.07469\n",
      "2017-07-04 23:13:27,237 INFO : valid_sample_misclass     0.15575\n",
      "2017-07-04 23:13:27,238 INFO : test_sample_misclass      0.29652\n",
      "2017-07-04 23:13:27,240 INFO : train_misclass            0.05000\n",
      "2017-07-04 23:13:27,241 INFO : valid_misclass            0.08333\n",
      "2017-07-04 23:13:27,243 INFO : test_misclass             0.26667\n",
      "2017-07-04 23:13:27,244 INFO : runtime                   2.16245\n",
      "2017-07-04 23:13:27,246 INFO : \n",
      "2017-07-04 23:13:29,297 INFO : Epoch 24\n",
      "2017-07-04 23:13:29,300 INFO : train_loss                0.12348\n",
      "2017-07-04 23:13:29,301 INFO : valid_loss                0.28360\n",
      "2017-07-04 23:13:29,303 INFO : test_loss                 0.78044\n",
      "2017-07-04 23:13:29,304 INFO : train_sample_misclass     0.03632\n",
      "2017-07-04 23:13:29,306 INFO : valid_sample_misclass     0.10495\n",
      "2017-07-04 23:13:29,307 INFO : test_sample_misclass      0.28529\n",
      "2017-07-04 23:13:29,309 INFO : train_misclass            0.03333\n",
      "2017-07-04 23:13:29,310 INFO : valid_misclass            0.08333\n",
      "2017-07-04 23:13:29,312 INFO : test_misclass             0.26667\n",
      "2017-07-04 23:13:29,314 INFO : runtime                   2.06987\n",
      "2017-07-04 23:13:29,315 INFO : \n",
      "2017-07-04 23:13:31,330 INFO : Epoch 25\n",
      "2017-07-04 23:13:31,332 INFO : train_loss                0.14715\n",
      "2017-07-04 23:13:31,333 INFO : valid_loss                0.19253\n",
      "2017-07-04 23:13:31,335 INFO : test_loss                 0.77622\n",
      "2017-07-04 23:13:31,336 INFO : train_sample_misclass     0.04635\n",
      "2017-07-04 23:13:31,338 INFO : valid_sample_misclass     0.05660\n",
      "2017-07-04 23:13:31,339 INFO : test_sample_misclass      0.26863\n",
      "2017-07-04 23:13:31,341 INFO : train_misclass            0.05000\n",
      "2017-07-04 23:13:31,342 INFO : valid_misclass            0.08333\n",
      "2017-07-04 23:13:31,344 INFO : test_misclass             0.23333\n",
      "2017-07-04 23:13:31,345 INFO : runtime                   2.02540\n",
      "2017-07-04 23:13:31,347 INFO : \n",
      "2017-07-04 23:13:33,286 INFO : Epoch 26\n",
      "2017-07-04 23:13:33,289 INFO : train_loss                0.33871\n",
      "2017-07-04 23:13:33,290 INFO : valid_loss                0.33738\n",
      "2017-07-04 23:13:33,292 INFO : test_loss                 0.75611\n",
      "2017-07-04 23:13:33,293 INFO : train_sample_misclass     0.16430\n",
      "2017-07-04 23:13:33,295 INFO : valid_sample_misclass     0.16689\n",
      "2017-07-04 23:13:33,297 INFO : test_sample_misclass      0.27763\n",
      "2017-07-04 23:13:33,298 INFO : train_misclass            0.11667\n",
      "2017-07-04 23:13:33,300 INFO : valid_misclass            0.16667\n",
      "2017-07-04 23:13:33,301 INFO : test_misclass             0.26667\n",
      "2017-07-04 23:13:33,303 INFO : runtime                   1.97666\n",
      "2017-07-04 23:13:33,304 INFO : \n",
      "2017-07-04 23:13:35,415 INFO : Epoch 27\n",
      "2017-07-04 23:13:35,418 INFO : train_loss                0.12510\n",
      "2017-07-04 23:13:35,419 INFO : valid_loss                0.14954\n",
      "2017-07-04 23:13:35,421 INFO : test_loss                 0.60954\n",
      "2017-07-04 23:13:35,422 INFO : train_sample_misclass     0.03111\n",
      "2017-07-04 23:13:35,424 INFO : valid_sample_misclass     0.02718\n",
      "2017-07-04 23:13:35,425 INFO : test_sample_misclass      0.23351\n",
      "2017-07-04 23:13:35,427 INFO : train_misclass            0.01667\n",
      "2017-07-04 23:13:35,428 INFO : valid_misclass            0.00000\n",
      "2017-07-04 23:13:35,430 INFO : test_misclass             0.16667\n",
      "2017-07-04 23:13:35,432 INFO : runtime                   2.10215\n",
      "2017-07-04 23:13:35,433 INFO : \n",
      "2017-07-04 23:13:37,399 INFO : Epoch 28\n",
      "2017-07-04 23:13:37,401 INFO : train_loss                0.09142\n",
      "2017-07-04 23:13:37,403 INFO : valid_loss                0.15033\n",
      "2017-07-04 23:13:37,404 INFO : test_loss                 0.64889\n",
      "2017-07-04 23:13:37,406 INFO : train_sample_misclass     0.01239\n",
      "2017-07-04 23:13:37,407 INFO : valid_sample_misclass     0.03387\n",
      "2017-07-04 23:13:37,409 INFO : test_sample_misclass      0.25856\n",
      "2017-07-04 23:13:37,410 INFO : train_misclass            0.00000\n",
      "2017-07-04 23:13:37,412 INFO : valid_misclass            0.00000\n",
      "2017-07-04 23:13:37,413 INFO : test_misclass             0.26667\n",
      "2017-07-04 23:13:37,415 INFO : runtime                   1.98700\n",
      "2017-07-04 23:13:37,416 INFO : \n",
      "2017-07-04 23:13:39,357 INFO : Epoch 29\n",
      "2017-07-04 23:13:39,359 INFO : train_loss                0.12668\n",
      "2017-07-04 23:13:39,361 INFO : valid_loss                0.21722\n",
      "2017-07-04 23:13:39,362 INFO : test_loss                 0.74796\n",
      "2017-07-04 23:13:39,364 INFO : train_sample_misclass     0.04274\n",
      "2017-07-04 23:13:39,365 INFO : valid_sample_misclass     0.08623\n",
      "2017-07-04 23:13:39,367 INFO : test_sample_misclass      0.26399\n",
      "2017-07-04 23:13:39,368 INFO : train_misclass            0.03333\n",
      "2017-07-04 23:13:39,370 INFO : valid_misclass            0.08333\n",
      "2017-07-04 23:13:39,371 INFO : test_misclass             0.23333\n",
      "2017-07-04 23:13:39,373 INFO : runtime                   1.96089\n",
      "2017-07-04 23:13:39,374 INFO : \n",
      "2017-07-04 23:13:41,318 INFO : Epoch 30\n",
      "2017-07-04 23:13:41,320 INFO : train_loss                0.07407\n",
      "2017-07-04 23:13:41,322 INFO : valid_loss                0.15270\n",
      "2017-07-04 23:13:41,323 INFO : test_loss                 0.67133\n",
      "2017-07-04 23:13:41,325 INFO : train_sample_misclass     0.01497\n",
      "2017-07-04 23:13:41,326 INFO : valid_sample_misclass     0.06061\n",
      "2017-07-04 23:13:41,328 INFO : test_sample_misclass      0.23975\n",
      "2017-07-04 23:13:41,329 INFO : train_misclass            0.01667\n",
      "2017-07-04 23:13:41,331 INFO : valid_misclass            0.08333\n",
      "2017-07-04 23:13:41,332 INFO : test_misclass             0.20000\n",
      "2017-07-04 23:13:41,334 INFO : runtime                   1.96380\n",
      "2017-07-04 23:13:41,335 INFO : \n",
      "2017-07-04 23:13:43,245 INFO : Epoch 31\n",
      "2017-07-04 23:13:43,248 INFO : train_loss                0.05036\n",
      "2017-07-04 23:13:43,249 INFO : valid_loss                0.09103\n",
      "2017-07-04 23:13:43,251 INFO : test_loss                 0.66769\n",
      "2017-07-04 23:13:43,252 INFO : train_sample_misclass     0.00744\n",
      "2017-07-04 23:13:43,253 INFO : valid_sample_misclass     0.02317\n",
      "2017-07-04 23:13:43,255 INFO : test_sample_misclass      0.20677\n",
      "2017-07-04 23:13:43,256 INFO : train_misclass            0.00000\n",
      "2017-07-04 23:13:43,258 INFO : valid_misclass            0.00000\n",
      "2017-07-04 23:13:43,259 INFO : test_misclass             0.20000\n",
      "2017-07-04 23:13:43,261 INFO : runtime                   1.92206\n",
      "2017-07-04 23:13:43,262 INFO : \n"
     ]
    }
   ],
   "source": [
    "# need to setup python logging before to be able to see anything\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this case, we arrive at 80.0% accuracy, the training stops after the validation loss decreases below the training loss at the best epoch of 0.03722."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dataset References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " This dataset was created and contributed to PhysioNet by the developers of the [BCI2000](http://www.schalklab.org/research/bci2000) instrumentation system, which they used in making these recordings. The system is described in:\n",
    " \n",
    "     Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. (2004) BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE TBME 51(6):1034-1043.\n",
    "\n",
    "[PhysioBank](https://physionet.org/physiobank/) is a large and growing archive of well-characterized digital recordings of physiologic signals and related data for use by the biomedical research community and further described in:\n",
    "\n",
    "    Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000) PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
