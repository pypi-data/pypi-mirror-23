# Filename: piscoreanalysis.py
# Author: Thomas H. Smith 2017
"""
Small collection of functions used for statistical analysis
of phosphoproteomics datasets with row-wise intensity values
with at least two replicates from each experimental condition
"""

from scipy import stats
from numpy import var, mean, log2, log10, ones
from tqdm import tqdm_notebook, tqdm_pandas, tqdm

def _excel_f_test(x_array, y_array):
    """
    Implementation of the Excel FTEST function for testing
    between-group variance of two arrays of values from
    replicates from two different experimental conditions.

    Parameters
    ----------
    x_array : a list of float
        First list of values for comparison
    y_array : a list of float
        Second list of values for comparison

    Returns
    -------
    p_val : float
        The p-value repreesnting the liklihood that the
        two input float sets have equal variances. e.g.
        p < 0.05 indicates that there is a 5% liklihood
        that the two arrays would have equal variances
        by random chance alone.

    """

    if (var(x_array)) < (var(y_array)):
        x_array, y_array = y_array, x_array
    degfree_x = float(len(x_array) - 1)
    degfree_y = float(len(y_array) - 1)
    x_mean = mean(x_array)
    y_mean = mean(y_array)
    x_var = (1/degfree_x) * sum([(xi-x_mean)**2 for xi in x_array])
    y_var = (1/degfree_y) * sum([(yi-y_mean)**2 for yi in y_array])
    f_value = x_var/y_var
    p_val = (1 - stats.f.cdf(f_value, degfree_x, degfree_y)) * 2
    return p_val


# Perform t-test comparing control vs treated samples
# based on F-test, use welch's or student's
def _smart_t_test(x_array, y_array):
    """
    Test the null hypothesis that two sets of values
    are from the same population (ie they do not
    exhibit a statistitically significant difference)
    using either Student's t-test or Welchs's t-test if
    the the sets have equal or unequal variances (as
    assessed by FTEST), respectively.

    Parameters
    ----------
    x_array : a list of float
        First list of values for comparison
    y_array : a list of float
        Second list of values for comparison

    Returns
    -------
    p-value: float
        p-value calculated from appropriate t-test

    """
    # Determine whether samples have equal variance
    f_test_pval = _excel_f_test(x_array, y_array)
    # If p-val from F-test is > 0.05, the samples have
    # equal variance, so use Student's t-test
    if f_test_pval > 0.05:
        return stats.ttest_ind(x_array, y_array, equal_var=True)[1]
    # If samples have unequal variance, use Welch's t-test
    else:
        return stats.ttest_ind(x_array, y_array, equal_var=False)[1]

def _calc_log2_fc(ctrl, treated):
    fold_change = (treated/ctrl)
    return log2(fold_change)


def _assign_alpha_value(pi_score):
    signif = False
    alpha_levels = [0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002, 0.0001]
    critvals = {0.05:1.1082, 0.02:1.6657, 0.01:2.1270, 0.005:2.6138, 0.002:3.29839,
                0.001:3.8434, 0.0005:4.4122, 0.0002:5.1559, 0.0001:5.7964}
    for level in alpha_levels:
        if pi_score > critvals[level]:
            alpha_val = level
            signif = True
    if signif:
        return alpha_val
    else:
        return 'ns'

def pi_score_analysis(_df, ctrl_cols, treated_cols, add_f_test_col=False, fc_reps=True,
                      add_alpha_level_col=True, label='', summarize=True):
    """
    Generate pi-scores and associated significance levels based
    on published table of critical pi-score values with alpha values.
    Add data as new columns to the input Pandas DataFrame.

    Parameters
    ----------
    _df : pandas.DataFrame
        Input DataFrame containing dataset to be analyzed
    ctrl_cols : list of str
        List of names of the columns in input df that contain
        replicate values for control condition.
    treated_cols : list of str
        List of names of the columns in input df that contain
        replicate values for treated condition.
    add_FTest_col : bool, optional
        Adds column to return df containing FTEST p values.
    add_alpha_level_col : bool, optional
        Adds a column to return df containing the alpha values
        (ie significance levels) as determined by a published
        table of critical pi-scores corresponding to alphas.
    label : str, optional
        Label to append to the new columns generated by the
        pi-score analysis, usually a descriptor of the
        experimental condition, ie 'APC_30'
    summarize : bool, optional
        Print summary of significance after analysis

    Returns
    -------
    df : pandas.DataFrame
        Copy of input DataFrame, but with additional columns
        containing p-values, pi-scores, and alpha significance
        levels (optional).

    Examples
    --------
    >>> from PhosphoStats import pi_score_stats
    >>> cond1_cols = ['Thr0_1', 'Thr0_2', 'Thr0_3']
    >>> cond2_cols = ['Thr5_1', 'Thr5_2', 'Thr5_3']
    >>> df = pi_score_stats(df, cond1_cols, cond2_cols, label='Thr5')

    """

    df_in = _df.copy()
    pval_label, log2fc_avg_label = ('pval_%s' % label), ('log2FC_%s_avg' % label)
    pi_score, alpha_col = ('pi_score_%s' % label), ('alpha_signif_%s' % label)
    if add_f_test_col:
        f_test_col = 'F_Test_%s' % label
        df_in[f_test_label] = df_in.apply(lambda row:
                                          _excel_f_test(row[ctrl_cols],
                                                        row[treated_cols]), axis=1)
    print 'Performing t-tests...'
    df_in[pval_label] = df_in.apply(lambda row:
                                    _smart_t_test(row[ctrl_cols],
                                                  row[treated_cols]), axis=1)
    rep_fc_labels = []
    print 'Calculating log2(fold-change) values for individual replicates...'
    for i in range(len(ctrl_cols)):
        rep_label = 'log2FC_%s_rep%d' % (label, i)
        df_in[rep_label] = df_in.apply(lambda row:
                                        _calc_log2_fc(row[ctrl_cols[i]],
                                                          row[treated_cols[i]]), axis=1)
        rep_fc_labels.append(rep_label)
        df_in[log2fc_avg_label] = df_in.apply(lambda row:
                                              mean([x for x in row[rep_fc_labels]]), axis=1)
    print 'Calculating pi-scores...'
    df_in[pi_score] = df_in.apply(lambda row:
                                  abs(row[log2fc_avg_label])*
                                  (-log10(row[pval_label])), axis=1)
        # If unequal replicates btwn ctrl/treated, calculate avg fold-change for each
        # row, not individual replicates

    if add_alpha_level_col:
        print 'Assigning alpha significance level values...'
        vals_indices = df_in[~df_in[treated_cols[0]].isnull()].index
        df_in.loc[vals_indices, alpha_col] = df_in[pi_score].apply(lambda x: _assign_alpha_value(x))

    if summarize:
        signif_slice = df_in[~df_in[alpha_col].isnull()].copy()
        total = len(signif_slice)
        alpha_levels = signif_slice[alpha_col].unique()
        for level in alpha_levels:
            n = len(signif_slice[signif_slice[alpha_col] == level])
            n_unique = len(signif_slice[signif_slice[alpha_col] == level]['Protein'].unique())
            pct = (float(n)/total) * 100
            print '%s:\t%d\t(%.2f%%) phosphopeptides from %d unique proteins' % (level, n, pct, n_unique)
        total_n_signif = len(signif_slice[signif_slice[alpha_col] != 'ns'])
        total_signif_pct = (float(total_n_signif)/total)*100
        total_signif_unique = len(signif_slice[signif_slice[alpha_col] != 'ns']['Protein'].unique())
        print '-'*65
        print '< 0.05:\t%d\t(%.2f%%) phosphopeptides from %d unique proteins' % (total_n_signif, total_signif_pct,
                                                                                 total_signif_unique)
        print 'Total:\t%d\t(------) phosphopeptides from %d unique proteins' % (total,
                                                                               len(signif_slice['Protein'].unique()))

    return df_in



# Perform multiple hypothesis test using Benjamini-Hochberg (B-H) procedure
# which uses p-value rankings and a target FDR cutoff to minimize
# type 1 errors (false positives)
# Calculate each p-value's critical value as: (i/m)*Q, where:
# i = invidiaul p-value's rank; m = total number of tests; Q = desired false discover rate
# then find largest p-val that is smaller than the critical value, anything above is significant

def bh_procedure(_df, p_col, q_fdr):
    """
    *** NOT USED ***
    Performs multiple hypothesis test using Benjamini-Hovchberg (BH)
    procedure, which uses p-val rankings and a target FDR cutoff
    to minize type 1 errors (false positives). Critical values are
    determined for each p-val as: (i/m)*Q, where i = p-val rank;
    m = total # of tests; Q = desired FDR. Test then finds largest
    p-val that is smaller than its critical value, anything p-vals
    above that point (e.g. smaller) are considered significant

    Parameters
    ----------
    _df : pandas.DataFrame
        Input DataFrame containing data to be tested
    p_col : str
        Label of the p-value column in the input df
    q_fdr : int or float
        False discovery rate (FDR) cut-off, higher
        values will consider more samples as significant
        lower values are more stringent

    Returns
    -------
    df_bh : pandas.DataFrame
        Copy of the input df containing additional columns
        containing p-val ranks and significance as determined
        by BH multiple hypothesis test at the given FDR.

    """
    bh_signif_label = 'BH_signif_%d' % q_fdr
    df_bh = _df.sort_values(p_col).copy()
    df_bh['p_rank'] = range(1, len(df_bh)+1)
    m_val = float(len(df_bh))
    df_bh['BH_cval'] = df_bh['p_rank'].apply(lambda i: (i/m_val)*q_fdr)
    df_bh[bh_signif_label] = zeros(len(df_bh))
    indices = range(len(df_bh)-1, -1, -1)
    for index in indices:
        if df_bh.iloc[index][p_col] < df_bh.iloc[index]['BH_cval']:
            df_bh.loc[0:index, bh_signif_label] = 1
            return df_bh.drop('BH_cval', axis=1)
    return df_bh.drop('BH_cval', axis=1)


# Calculate adjusted p-value for each row
# Adjust p-value is equal to the lower of:
# p_adj = (p_raw) * (m / i) , where m = total # of samples, and i = p_value rank
# OR the p_adj value calculated for the NEXT highest ranked p value
# If p_adj is lower than FDR, then the test is considered significant
def calc_bh_p_adj(_df, p_raw_col, q_fdr, p_adj_colname, signif_col=False):
    """
    *** NOT USED ***
    Performs multiple hypothesis test using Benjamini-Hovchberg (BH)
    like above, but also assigns adjusted p-values

    Parameters
    ----------
    _df : pandas.DataFrame
        Input DataFrame containing data to be tested
    p_col : str
        Label of the p-value column in the input df
    q_fdr : int or float
        False discovery rate (FDR) cut-off, higher
        values will consider more samples as significant
        lower values are more stringent
    p_adj_colname : str
        Name to assign to the new column for adjust p-values
    signif_col : boolean
        Whether to include a boolean column specifying
        which rows are significant

    Returns
    -------
    df_bh : pandas.DataFrame
        Copy of the input df containing additional columns
        containing p-val ranks and significance as determined
        by BH multiple hypothesis test at the given FDR.

    """

    adj_p_dict = {}
    df_bh = bh_procedure(_df, p_raw_col, q_fdr)
    df_p_adj = df_bh.sort_values('p_rank').copy()
    # iterate from bottom of df (starting with highest p-value)
    # the bottom row is forced to equal (p_raw) * (m/i), as there is no next higher ranked p-val
    m_val = len(df_p_adj)
    adj_p_dict[(m_val-1)] = (df_p_adj.iloc[
        (m_val-1)][p_raw_col])*(m_val/float(df_p_adj.iloc[(m-1)]['p_rank']))
    indices = range((m-2), -1, -1)
    for index in indices:
        adj_pval = (df_p_adj.iloc[index][p_raw_col])*(m/float((df_p_adj.iloc[index]['p_rank'])))

        if adj_pval < adj_p_dict[(index+1)]:
            adj_p_dict[index] = adj_pval
        else:
            adj_p_dict[index] = adj_p_dict[index+1]
    df_p_adj[p_adj_colname] = adj_p_dict.values()
    if signif_col:
        return df_p_adj.drop('p_rank', axis=1)
    else:
        return df_p_adj.drop(['significant', 'p_rank'], axis=1)

